{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 1 is: 41642.675471326074\n",
      "Loss at iteration 2 is: 40768.99992754794\n",
      "Loss at iteration 3 is: 39914.62607978486\n",
      "Loss at iteration 4 is: 39079.106620873325\n",
      "Loss at iteration 5 is: 38262.00506540894\n",
      "Loss at iteration 6 is: 37462.89547787846\n",
      "Loss at iteration 7 is: 36681.36220784538\n",
      "Loss at iteration 8 is: 35916.99963200168\n",
      "Loss at iteration 9 is: 35169.41190290223\n",
      "Loss at iteration 10 is: 34438.212704204176\n",
      "Loss at iteration 11 is: 33723.02501223823\n",
      "Loss at iteration 12 is: 33023.480863743476\n",
      "Loss at iteration 13 is: 32339.221129601872\n",
      "Loss at iteration 14 is: 31669.89529441314\n",
      "Loss at iteration 15 is: 31015.161241755013\n",
      "Loss at iteration 16 is: 30374.685044978036\n",
      "Loss at iteration 17 is: 29748.140763388332\n",
      "Loss at iteration 18 is: 29135.210243675396\n",
      "Loss at iteration 19 is: 28535.582926446245\n",
      "Loss at iteration 20 is: 27948.955657730745\n",
      "Loss at iteration 21 is: 27375.03250532675\n",
      "Loss at iteration 22 is: 26813.524579857127\n",
      "Loss at iteration 23 is: 26264.14986041418\n",
      "Loss at iteration 24 is: 25726.633024670668\n",
      "Loss at iteration 25 is: 25200.705283339325\n",
      "Loss at iteration 26 is: 24686.104218866574\n",
      "Loss at iteration 27 is: 24182.57362824872\n",
      "Loss at iteration 28 is: 23689.863369862218\n",
      "Loss at iteration 29 is: 23207.729214202496\n",
      "Loss at iteration 30 is: 22735.932698428507\n",
      "Loss at iteration 31 is: 22274.240984613116\n",
      "Loss at iteration 32 is: 21822.42672160209\n",
      "Loss at iteration 33 is: 21380.267910386887\n",
      "Loss at iteration 34 is: 20947.547772899445\n",
      "Loss at iteration 35 is: 20524.054624138942\n",
      "Loss at iteration 36 is: 20109.581747543707\n",
      "Loss at iteration 37 is: 19703.927273523077\n",
      "Loss at iteration 38 is: 19306.894061066865\n",
      "Loss at iteration 39 is: 18918.289582351805\n",
      "Loss at iteration 40 is: 18537.925810267\n",
      "Loss at iteration 41 is: 18165.619108781975\n",
      "Loss at iteration 42 is: 17801.19012608348\n",
      "Loss at iteration 43 is: 17444.463690408717\n",
      "Loss at iteration 44 is: 17095.26870850497\n",
      "Loss at iteration 45 is: 16753.43806664721\n",
      "Loss at iteration 46 is: 16418.80853414724\n",
      "Loss at iteration 47 is: 16091.220669289673\n",
      "Loss at iteration 48 is: 15770.518727631697\n",
      "Loss at iteration 49 is: 15456.5505726054\n",
      "Loss at iteration 50 is: 15149.167588362896\n",
      "Loss at iteration 51 is: 14848.224594806237\n",
      "Loss at iteration 52 is: 14553.57976474549\n",
      "Loss at iteration 53 is: 14265.094543130017\n",
      "Loss at iteration 54 is: 13982.633568299372\n",
      "Loss at iteration 55 is: 13706.064595201555\n",
      "Loss at iteration 56 is: 13435.258420528005\n",
      "Loss at iteration 57 is: 13170.088809715835\n",
      "Loss at iteration 58 is: 12910.432425769159\n",
      "Loss at iteration 59 is: 12656.168759852735\n",
      "Loss at iteration 60 is: 12407.180063612332\n",
      "Loss at iteration 61 is: 12163.351283177328\n",
      "Loss at iteration 62 is: 11924.569994802465\n",
      "Loss at iteration 63 is: 11690.726342106578\n",
      "Loss at iteration 64 is: 11461.71297486734\n",
      "Loss at iteration 65 is: 11237.424989332212\n",
      "Loss at iteration 66 is: 11017.75987000666\n",
      "Loss at iteration 67 is: 10802.617432881965\n",
      "Loss at iteration 68 is: 10591.8997700656\n",
      "Loss at iteration 69 is: 10385.51119577861\n",
      "Loss at iteration 70 is: 10183.358193684824\n",
      "Loss at iteration 71 is: 9985.3493655181\n",
      "Loss at iteration 72 is: 9791.395380974394\n",
      "Loss at iteration 73 is: 9601.408928836521\n",
      "Loss at iteration 74 is: 9415.304669300165\n",
      "Loss at iteration 75 is: 9232.99918747061\n",
      "Loss at iteration 76 is: 9054.410948000383\n",
      "Loss at iteration 77 is: 8879.460250838965\n",
      "Loss at iteration 78 is: 8708.069188066205\n",
      "Loss at iteration 79 is: 8540.161601782027\n",
      "Loss at iteration 80 is: 8375.663043025628\n",
      "Loss at iteration 81 is: 8214.50073169823\n",
      "Loss at iteration 82 is: 8056.603517463761\n",
      "Loss at iteration 83 is: 7901.901841603025\n",
      "Loss at iteration 84 is: 7750.327699796999\n",
      "Loss at iteration 85 is: 7601.814605816111\n",
      "Loss at iteration 86 is: 7456.297556092324\n",
      "Loss at iteration 87 is: 7313.712995152111\n",
      "Loss at iteration 88 is: 7173.998781888359\n",
      "Loss at iteration 89 is: 7037.094156650312\n",
      "Loss at iteration 90 is: 6902.939709130858\n",
      "Loss at iteration 91 is: 6771.477347031243\n",
      "Loss at iteration 92 is: 6642.650265483562\n",
      "Loss at iteration 93 is: 6516.402917212189\n",
      "Loss at iteration 94 is: 6392.680983415505\n",
      "Loss at iteration 95 is: 6271.4313453499635\n",
      "Loss at iteration 96 is: 6152.602056598913\n",
      "Loss at iteration 97 is: 6036.142316009014\n",
      "Loss at iteration 98 is: 5922.00244127768\n",
      "Loss at iteration 99 is: 5810.133843175192\n",
      "Loss at iteration 100 is: 5700.4890003857545\n",
      "Loss at iteration 101 is: 5593.021434951992\n",
      "Loss at iteration 102 is: 5487.685688307952\n",
      "Loss at iteration 103 is: 5384.437297885905\n",
      "Loss at iteration 104 is: 5283.2327742827465\n",
      "Loss at iteration 105 is: 5184.029578972069\n",
      "Loss at iteration 106 is: 5086.786102548358\n",
      "Loss at iteration 107 is: 4991.461643490196\n",
      "Loss at iteration 108 is: 4898.016387429521\n",
      "Loss at iteration 109 is: 4806.4113869145085\n",
      "Loss at iteration 110 is: 4716.608541653817\n",
      "Loss at iteration 111 is: 4628.570579230325\n",
      "Loss at iteration 112 is: 4542.261036272789\n",
      "Loss at iteration 113 is: 4457.644240074106\n",
      "Loss at iteration 114 is: 4374.685290645182\n",
      "Loss at iteration 115 is: 4293.350043193716\n",
      "Loss at iteration 116 is: 4213.605091017387\n",
      "Loss at iteration 117 is: 4135.417748801328\n",
      "Loss at iteration 118 is: 4058.756036309913\n",
      "Loss at iteration 119 is: 3983.588662463204\n",
      "Loss at iteration 120 is: 3909.8850097886334\n",
      "Loss at iteration 121 is: 3837.615119238715\n",
      "Loss at iteration 122 is: 3766.7496753658493\n",
      "Loss at iteration 123 is: 3697.25999184548\n",
      "Loss at iteration 124 is: 3629.1179973390963\n",
      "Loss at iteration 125 is: 3562.296221688785\n",
      "Loss at iteration 126 is: 3496.7677824352695\n",
      "Loss at iteration 127 is: 3432.5063716515074\n",
      "Loss at iteration 128 is: 3369.4862430842277\n",
      "Loss at iteration 129 is: 3307.682199595868\n",
      "Loss at iteration 130 is: 3247.069580899647\n",
      "Loss at iteration 131 is: 3187.624251580621\n",
      "Loss at iteration 132 is: 3129.3225893958506\n",
      "Loss at iteration 133 is: 3072.141473846821\n",
      "Loss at iteration 134 is: 3016.05827501763\n",
      "Loss at iteration 135 is: 2961.0508426724173\n",
      "Loss at iteration 136 is: 2907.097495605857\n",
      "Loss at iteration 137 is: 2854.177011240514\n",
      "Loss at iteration 138 is: 2802.268615465209\n",
      "Loss at iteration 139 is: 2751.351972708484\n",
      "Loss at iteration 140 is: 2701.407176241576\n",
      "Loss at iteration 141 is: 2652.4147387053545\n",
      "Loss at iteration 142 is: 2604.3555828558297\n",
      "Loss at iteration 143 is: 2557.2110325229987\n",
      "Loss at iteration 144 is: 2510.9628037778957\n",
      "Loss at iteration 145 is: 2465.5929963028657\n",
      "Loss at iteration 146 is: 2421.0840849601987\n",
      "Loss at iteration 147 is: 2377.418911554356\n",
      "Loss at iteration 148 is: 2334.580676783178\n",
      "Loss at iteration 149 is: 2292.5529323735736\n",
      "Loss at iteration 150 is: 2251.3195733972325\n",
      "Loss at iteration 151 is: 2210.864830762149\n",
      "Loss at iteration 152 is: 2171.1732638756916\n",
      "Loss at iteration 153 is: 2132.2297534751933\n",
      "Loss at iteration 154 is: 2094.0194946220477\n",
      "Loss at iteration 155 is: 2056.5279898554227\n",
      "Loss at iteration 156 is: 2019.741042501858\n",
      "Loss at iteration 157 is: 1983.6447501369391\n",
      "Loss at iteration 158 is: 1948.2254981955907\n",
      "Loss at iteration 159 is: 1913.4699537273366\n",
      "Loss at iteration 160 is: 1879.365059293185\n",
      "Loss at iteration 161 is: 1845.898027000754\n",
      "Loss at iteration 162 is: 1813.056332674396\n",
      "Loss at iteration 163 is: 1780.8277101571039\n",
      "Loss at iteration 164 is: 1749.2001457411575\n",
      "Loss at iteration 165 is: 1718.161872724381\n",
      "Loss at iteration 166 is: 1687.7013660891716\n",
      "Loss at iteration 167 is: 1657.8073373013249\n",
      "Loss at iteration 168 is: 1628.4687292258895\n",
      "Loss at iteration 169 is: 1599.6747111572945\n",
      "Loss at iteration 170 is: 1571.4146739610762\n",
      "Loss at iteration 171 is: 1543.6782253245817\n",
      "Loss at iteration 172 is: 1516.4551851141202\n",
      "Loss at iteration 173 is: 1489.7355808360442\n",
      "Loss at iteration 174 is: 1463.5096431993738\n",
      "Loss at iteration 175 is: 1437.767801777566\n",
      "Loss at iteration 176 is: 1412.5006807671239\n",
      "Loss at iteration 177 is: 1387.6990948408034\n",
      "Loss at iteration 178 is: 1363.354045093206\n",
      "Loss at iteration 179 is: 1339.4567150766215\n",
      "Loss at iteration 180 is: 1315.9984669250093\n",
      "Loss at iteration 181 is: 1292.970837564092\n",
      "Loss at iteration 182 is: 1270.3655350055606\n",
      "Loss at iteration 183 is: 1248.1744347234321\n",
      "Loss at iteration 184 is: 1226.3895761106828\n",
      "Loss at iteration 185 is: 1205.0031590142808\n",
      "Loss at iteration 186 is: 1184.0075403468213\n",
      "Loss at iteration 187 is: 1163.395230772991\n",
      "Loss at iteration 188 is: 1143.158891469144\n",
      "Loss at iteration 189 is: 1123.2913309543023\n",
      "Loss at iteration 190 is: 1103.7855019909357\n",
      "Loss at iteration 191 is: 1084.6344985539272\n",
      "Loss at iteration 192 is: 1065.8315528661492\n",
      "Loss at iteration 193 is: 1047.370032499125\n",
      "Loss at iteration 194 is: 1029.2434375372954\n",
      "Loss at iteration 195 is: 1011.4453978044137\n",
      "Loss at iteration 196 is: 993.969670150674\n",
      "Loss at iteration 197 is: 976.8101357991576\n",
      "Loss at iteration 198 is: 959.9607977502714\n",
      "Loss at iteration 199 is: 943.4157782428324\n",
      "Loss at iteration 200 is: 927.1693162705265\n",
      "Loss at iteration 201 is: 911.2157651524681\n",
      "Loss at iteration 202 is: 895.5495901566342\n",
      "Loss at iteration 203 is: 880.165366174981\n",
      "Loss at iteration 204 is: 865.0577754490512\n",
      "Loss at iteration 205 is: 850.2216053449495\n",
      "Loss at iteration 206 is: 835.6517461765493\n",
      "Loss at iteration 207 is: 821.34318907585\n",
      "Loss at iteration 208 is: 807.2910239094158\n",
      "Loss at iteration 209 is: 793.4904372398539\n",
      "Loss at iteration 210 is: 779.9367103313182\n",
      "Loss at iteration 211 is: 766.625217198045\n",
      "Loss at iteration 212 is: 753.5514226949516\n",
      "Loss at iteration 213 is: 740.7108806493468\n",
      "Loss at iteration 214 is: 728.099232032845\n",
      "Loss at iteration 215 is: 715.7122031725521\n",
      "Loss at iteration 216 is: 703.5456040006752\n",
      "Loss at iteration 217 is: 691.5953263416715\n",
      "Loss at iteration 218 is: 679.8573422361044\n",
      "Loss at iteration 219 is: 668.327702300383\n",
      "Loss at iteration 220 is: 657.0025341215877\n",
      "Loss at iteration 221 is: 645.8780406865912\n",
      "Loss at iteration 222 is: 634.9504988447169\n",
      "Loss at iteration 223 is: 624.2162578031832\n",
      "Loss at iteration 224 is: 613.6717376546001\n",
      "Loss at iteration 225 is: 603.3134279358138\n",
      "Loss at iteration 226 is: 593.1378862174008\n",
      "Loss at iteration 227 is: 583.1417367231145\n",
      "Loss at iteration 228 is: 573.3216689786566\n",
      "Loss at iteration 229 is: 563.6744364890731\n",
      "Loss at iteration 230 is: 554.1968554441919\n",
      "Loss at iteration 231 is: 544.8858034514421\n",
      "Loss at iteration 232 is: 535.7382182954757\n",
      "Loss at iteration 233 is: 526.7510967239853\n",
      "Loss at iteration 234 is: 517.9214932591433\n",
      "Loss at iteration 235 is: 509.2465190341076\n",
      "Loss at iteration 236 is: 500.72334065402305\n",
      "Loss at iteration 237 is: 492.3491790809967\n",
      "Loss at iteration 238 is: 484.12130854251643\n",
      "Loss at iteration 239 is: 476.037055462789\n",
      "Loss at iteration 240 is: 468.0937974165081\n",
      "Loss at iteration 241 is: 460.2889621045466\n",
      "Loss at iteration 242 is: 452.6200263511116\n",
      "Loss at iteration 243 is: 445.0845151218722\n",
      "Loss at iteration 244 is: 437.68000056261815\n",
      "Loss at iteration 245 is: 430.40410105799185\n",
      "Loss at iteration 246 is: 423.25448030985876\n",
      "Loss at iteration 247 is: 416.22884643488794\n",
      "Loss at iteration 248 is: 409.32495108092905\n",
      "Loss at iteration 249 is: 402.5405885617695\n",
      "Loss at iteration 250 is: 395.8735950098708\n",
      "Loss at iteration 251 is: 389.32184754671357\n",
      "Loss at iteration 252 is: 382.8832634703366\n",
      "Loss at iteration 253 is: 376.5557994597299\n",
      "Loss at iteration 254 is: 370.3374507956969\n",
      "Loss at iteration 255 is: 364.22625059783115\n",
      "Loss at iteration 256 is: 358.2202690772711\n",
      "Loss at iteration 257 is: 352.3176128048835\n",
      "Loss at iteration 258 is: 346.5164239945334\n",
      "Loss at iteration 259 is: 340.8148798011456\n",
      "Loss at iteration 260 is: 335.21119163320094\n",
      "Loss at iteration 261 is: 329.70360447938884\n",
      "Loss at iteration 262 is: 324.29039624909126\n",
      "Loss at iteration 263 is: 318.96987712641305\n",
      "Loss at iteration 264 is: 313.74038893746285\n",
      "Loss at iteration 265 is: 308.60030453060466\n",
      "Loss at iteration 266 is: 303.5480271693939\n",
      "Loss at iteration 267 is: 298.5819899379379\n",
      "Loss at iteration 268 is: 293.7006551584076\n",
      "Loss at iteration 269 is: 288.9025138204462\n",
      "Loss at iteration 270 is: 284.1860850222119\n",
      "Loss at iteration 271 is: 279.5499154228247\n",
      "Loss at iteration 272 is: 274.99257870595\n",
      "Loss at iteration 273 is: 270.51267505430485\n",
      "Loss at iteration 274 is: 266.1088306348439\n",
      "Loss at iteration 275 is: 261.7796970943941\n",
      "Loss at iteration 276 is: 257.5239510655308\n",
      "Loss at iteration 277 is: 253.3402936824637\n",
      "Loss at iteration 278 is: 249.22745010672725\n",
      "Loss at iteration 279 is: 245.1841690624715\n",
      "Loss at iteration 280 is: 241.20922238114252\n",
      "Loss at iteration 281 is: 237.3014045553622\n",
      "Loss at iteration 282 is: 233.459532301806\n",
      "Loss at iteration 283 is: 229.68244413289557\n",
      "Loss at iteration 284 is: 225.96899993711742\n",
      "Loss at iteration 285 is: 222.31808056778502\n",
      "Loss at iteration 286 is: 218.7285874400715\n",
      "Loss at iteration 287 is: 215.1994421361335\n",
      "Loss at iteration 288 is: 211.7295860181602\n",
      "Loss at iteration 289 is: 208.31797984918302\n",
      "Loss at iteration 290 is: 204.96360342147935\n",
      "Loss at iteration 291 is: 201.6654551924096\n",
      "Loss at iteration 292 is: 198.422551927545\n",
      "Loss at iteration 293 is: 195.2339283509158\n",
      "Loss at iteration 294 is: 192.0986368022458\n",
      "Loss at iteration 295 is: 189.01574690101967\n",
      "Loss at iteration 296 is: 185.98434521724582\n",
      "Loss at iteration 297 is: 183.00353494877064\n",
      "Loss at iteration 298 is: 180.07243560501124\n",
      "Loss at iteration 299 is: 177.190182696975\n",
      "Loss at iteration 300 is: 174.3559274334274\n",
      "Loss at iteration 301 is: 171.5688364230943\n",
      "Loss at iteration 302 is: 168.8280913827581\n",
      "Loss at iteration 303 is: 166.13288885113857\n",
      "Loss at iteration 304 is: 163.48243990843378\n",
      "Loss at iteration 305 is: 160.87596990139988\n",
      "Loss at iteration 306 is: 158.31271817386556\n",
      "Loss at iteration 307 is: 155.79193780255858\n",
      "Loss at iteration 308 is: 153.31289533814387\n",
      "Loss at iteration 309 is: 150.87487055135836\n",
      "Loss at iteration 310 is: 148.47715618414412\n",
      "Loss at iteration 311 is: 146.11905770567236\n",
      "Loss at iteration 312 is: 143.79989307316248\n",
      "Loss at iteration 313 is: 141.5189924973903\n",
      "Loss at iteration 314 is: 139.2756982128024\n",
      "Loss at iteration 315 is: 137.06936425212407\n",
      "Loss at iteration 316 is: 134.8993562253903\n",
      "Loss at iteration 317 is: 132.7650511032876\n",
      "Loss at iteration 318 is: 130.665837004739\n",
      "Loss at iteration 319 is: 128.60111298862947\n",
      "Loss at iteration 320 is: 126.57028884959558\n",
      "Loss at iteration 321 is: 124.57278491779894\n",
      "Loss at iteration 322 is: 122.60803186259216\n",
      "Loss at iteration 323 is: 120.67547050001065\n",
      "Loss at iteration 324 is: 118.77455160400153\n",
      "Loss at iteration 325 is: 116.90473572132252\n",
      "Loss at iteration 326 is: 115.06549299003339\n",
      "Loss at iteration 327 is: 113.25630296150155\n",
      "Loss at iteration 328 is: 111.47665442586091\n",
      "Loss at iteration 329 is: 109.72604524084724\n",
      "Loss at iteration 330 is: 108.00398216394272\n",
      "Loss at iteration 331 is: 106.30998068776594\n",
      "Loss at iteration 332 is: 104.6435648786374\n",
      "Loss at iteration 333 is: 103.00426721826113\n",
      "Loss at iteration 334 is: 101.39162844845686\n",
      "Loss at iteration 335 is: 99.80519741888043\n",
      "Loss at iteration 336 is: 98.24453093767715\n",
      "Loss at iteration 337 is: 96.7091936250037\n",
      "Loss at iteration 338 is: 95.19875776936397\n",
      "Loss at iteration 339 is: 93.71280318670358\n",
      "Loss at iteration 340 is: 92.25091708220401\n",
      "Loss at iteration 341 is: 90.8126939147253\n",
      "Loss at iteration 342 is: 89.39773526384501\n",
      "Loss at iteration 343 is: 88.00564969943855\n",
      "Loss at iteration 344 is: 86.63605265375247\n",
      "Loss at iteration 345 is: 85.28856629591951\n",
      "Loss at iteration 346 is: 83.96281940887224\n",
      "Loss at iteration 347 is: 82.65844726859473\n",
      "Loss at iteration 348 is: 81.37509152568069\n",
      "Loss at iteration 349 is: 80.11240008914477\n",
      "Loss at iteration 350 is: 78.87002701244099\n",
      "Loss at iteration 351 is: 77.64763238164721\n",
      "Loss at iteration 352 is: 76.44488220577348\n",
      "Loss at iteration 353 is: 75.26144830914927\n",
      "Loss at iteration 354 is: 74.09700822585214\n",
      "Loss at iteration 355 is: 72.9512450961331\n",
      "Loss at iteration 356 is: 71.82384756480414\n",
      "Loss at iteration 357 is: 70.71450968154352\n",
      "Loss at iteration 358 is: 69.62293080308778\n",
      "Loss at iteration 359 is: 68.54881549726753\n",
      "Loss at iteration 360 is: 67.49187344885215\n",
      "Loss at iteration 361 is: 66.45181936717188\n",
      "Loss at iteration 362 is: 65.42837289547471\n",
      "Loss at iteration 363 is: 64.42125852199243\n",
      "Loss at iteration 364 is: 63.4302054926755\n",
      "Loss at iteration 365 is: 62.454947725568246\n",
      "Loss at iteration 366 is: 61.49522372679125\n",
      "Loss at iteration 367 is: 60.55077650809608\n",
      "Loss at iteration 368 is: 59.62135350596911\n",
      "Loss at iteration 369 is: 58.706706502246256\n",
      "Loss at iteration 370 is: 57.806591546213525\n",
      "Loss at iteration 371 is: 56.92076887816453\n",
      "Loss at iteration 372 is: 56.049002854383545\n",
      "Loss at iteration 373 is: 55.19106187352989\n",
      "Loss at iteration 374 is: 54.346718304394855\n",
      "Loss at iteration 375 is: 53.51574841500256\n",
      "Loss at iteration 376 is: 52.69793230303277\n",
      "Loss at iteration 377 is: 51.89305382753663\n",
      "Loss at iteration 378 is: 51.10090054192171\n",
      "Loss at iteration 379 is: 50.32126362818156\n",
      "Loss at iteration 380 is: 49.55393783234523\n",
      "Loss at iteration 381 is: 48.79872140112284\n",
      "Loss at iteration 382 is: 48.055416019728206\n",
      "Loss at iteration 383 is: 47.32382675084694\n",
      "Loss at iteration 384 is: 46.603761974738504\n",
      "Loss at iteration 385 is: 45.89503333044178\n",
      "Loss at iteration 386 is: 45.19745565806811\n",
      "Loss at iteration 387 is: 44.51084694215867\n",
      "Loss at iteration 388 is: 43.83502825608545\n",
      "Loss at iteration 389 is: 43.16982370747809\n",
      "Loss at iteration 390 is: 42.51506038465345\n",
      "Loss at iteration 391 is: 41.87056830403194\n",
      "Loss at iteration 392 is: 41.236180358519675\n",
      "Loss at iteration 393 is: 40.611732266838516\n",
      "Loss at iteration 394 is: 39.99706252378592\n",
      "Loss at iteration 395 is: 39.39201235140754\n",
      "Loss at iteration 396 is: 38.79642565106293\n",
      "Loss at iteration 397 is: 38.21014895637051\n",
      "Loss at iteration 398 is: 37.63303138701184\n",
      "Loss at iteration 399 is: 37.06492460338153\n",
      "Loss at iteration 400 is: 36.50568276206387\n",
      "Loss at iteration 401 is: 35.95516247212441\n",
      "Loss at iteration 402 is: 35.41322275219595\n",
      "Loss at iteration 403 is: 34.879724988348194\n",
      "Loss at iteration 404 is: 34.354532892723974\n",
      "Loss at iteration 405 is: 33.837512462928736\n",
      "Loss at iteration 406 is: 33.32853194215723\n",
      "Loss at iteration 407 is: 32.82746178004493\n",
      "Loss at iteration 408 is: 32.33417459423032\n",
      "Loss at iteration 409 is: 31.848545132614785\n",
      "Loss at iteration 410 is: 31.37045023630504\n",
      "Loss at iteration 411 is: 30.89976880322857\n",
      "Loss at iteration 412 is: 30.43638175240584\n",
      "Loss at iteration 413 is: 29.98017198887003\n",
      "Loss at iteration 414 is: 29.531024369218944\n",
      "Loss at iteration 415 is: 29.088825667791077\n",
      "Loss at iteration 416 is: 28.653464543449427\n",
      "Loss at iteration 417 is: 28.224831506966126\n",
      "Loss at iteration 418 is: 27.802818888994025\n",
      "Loss at iteration 419 is: 27.387320808613907\n",
      "Loss at iteration 420 is: 26.97823314244972\n",
      "Loss at iteration 421 is: 26.57545349433503\n",
      "Loss at iteration 422 is: 26.178881165529027\n",
      "Loss at iteration 423 is: 25.788417125463486\n",
      "Loss at iteration 424 is: 25.40396398301573\n",
      "Loss at iteration 425 is: 25.02542595829607\n",
      "Loss at iteration 426 is: 24.652708854940492\n",
      "Loss at iteration 427 is: 24.28572003289983\n",
      "Loss at iteration 428 is: 23.92436838171359\n",
      "Loss at iteration 429 is: 23.568564294263453\n",
      "Loss at iteration 430 is: 23.21821964099395\n",
      "Loss at iteration 431 is: 22.873247744593627\n",
      "Loss at iteration 432 is: 22.533563355126773\n",
      "Loss at iteration 433 is: 22.19908262560986\n",
      "Loss at iteration 434 is: 21.8697230880205\n",
      "Loss at iteration 435 is: 21.545403629735066\n",
      "Loss at iteration 436 is: 21.226044470383414\n",
      "Loss at iteration 437 is: 20.91156713911687\n",
      "Loss at iteration 438 is: 20.60189445227671\n",
      "Loss at iteration 439 is: 20.296950491461963\n",
      "Loss at iteration 440 is: 19.996660581983207\n",
      "Loss at iteration 441 is: 19.700951271699033\n",
      "Loss at iteration 442 is: 19.409750310227608\n",
      "Loss at iteration 443 is: 19.12298662852463\n",
      "Loss at iteration 444 is: 18.840590318822777\n",
      "Loss at iteration 445 is: 18.562492614925883\n",
      "Loss at iteration 446 is: 18.288625872849188\n",
      "Loss at iteration 447 is: 18.018923551803187\n",
      "Loss at iteration 448 is: 17.753320195510376\n",
      "Loss at iteration 449 is: 17.491751413852484\n",
      "Loss at iteration 450 is: 17.234153864839897\n",
      "Loss at iteration 451 is: 16.9804652368979\n",
      "Loss at iteration 452 is: 16.730624231464823\n",
      "Loss at iteration 453 is: 16.484570545894968\n",
      "Loss at iteration 454 is: 16.242244856662076\n",
      "Loss at iteration 455 is: 16.003588802856754\n",
      "Loss at iteration 456 is: 15.768544969972902\n",
      "Loss at iteration 457 is: 15.53705687397909\n",
      "Loss at iteration 458 is: 15.309068945667049\n",
      "Loss at iteration 459 is: 15.084526515274414\n",
      "Loss at iteration 460 is: 14.863375797377117\n",
      "Loss at iteration 461 is: 14.645563876042594\n",
      "Loss at iteration 462 is: 14.431038690246105\n",
      "Loss at iteration 463 is: 14.219749019537538\n",
      "Loss at iteration 464 is: 14.011644469959883\n",
      "Loss at iteration 465 is: 13.806675460212075\n",
      "Loss at iteration 466 is: 13.60479320805316\n",
      "Loss at iteration 467 is: 13.405949716942095\n",
      "Loss at iteration 468 is: 13.210097762909708\n",
      "Loss at iteration 469 is: 13.017190881659545\n",
      "Loss at iteration 470 is: 12.82718335589084\n",
      "Loss at iteration 471 is: 12.64003020284163\n",
      "Loss at iteration 472 is: 12.455687162049998\n",
      "Loss at iteration 473 is: 12.274110683322503\n",
      "Loss at iteration 474 is: 12.095257914915504\n",
      "Loss at iteration 475 is: 11.919086691917837\n",
      "Loss at iteration 476 is: 11.745555524834813\n",
      "Loss at iteration 477 is: 11.574623588370297\n",
      "Loss at iteration 478 is: 11.40625071040028\n",
      "Loss at iteration 479 is: 11.240397361138823\n",
      "Loss at iteration 480 is: 11.077024642488428\n",
      "Loss at iteration 481 is: 10.916094277575816\n",
      "Loss at iteration 482 is: 10.757568600466065\n",
      "Loss at iteration 483 is: 10.601410546054248\n",
      "Loss at iteration 484 is: 10.447583640130542\n",
      "Loss at iteration 485 is: 10.29605198961656\n",
      "Loss at iteration 486 is: 10.146780272967607\n",
      "Loss at iteration 487 is: 9.999733730741795\n",
      "Loss at iteration 488 is: 9.854878156328112\n",
      "Loss at iteration 489 is: 9.712179886835056\n",
      "Loss at iteration 490 is: 9.571605794134886\n",
      "Loss at iteration 491 is: 9.43312327606008\n",
      "Loss at iteration 492 is: 9.296700247751552\n",
      "Loss at iteration 493 is: 9.162305133152962\n",
      "Loss at iteration 494 is: 9.02990685665192\n",
      "Loss at iteration 495 is: 8.899474834862328\n",
      "Loss at iteration 496 is: 8.770978968547167\n",
      "Loss at iteration 497 is: 8.644389634679424\n",
      "Loss at iteration 498 is: 8.51967767863695\n",
      "Loss at iteration 499 is: 8.396814406531222\n",
      "Loss at iteration 500 is: 8.275771577665529\n",
      "Loss at iteration 501 is: 8.156521397121747\n",
      "Loss at iteration 502 is: 8.039036508473025\n",
      "Loss at iteration 503 is: 7.923289986619631\n",
      "Loss at iteration 504 is: 7.809255330746174\n",
      "Loss at iteration 505 is: 7.696906457398978\n",
      "Loss at iteration 506 is: 7.586217693679451\n",
      "Loss at iteration 507 is: 7.4771637705534815\n",
      "Loss at iteration 508 is: 7.369719816273362\n",
      "Loss at iteration 509 is: 7.263861349911181\n",
      "Loss at iteration 510 is: 7.159564275001275\n",
      "Loss at iteration 511 is: 7.056804873289872\n",
      "Loss at iteration 512 is: 6.955559798590274\n",
      "Loss at iteration 513 is: 6.855806070741167\n",
      "Loss at iteration 514 is: 6.757521069667134\n",
      "Loss at iteration 515 is: 6.660682529538978\n",
      "Loss at iteration 516 is: 6.565268533032041\n",
      "Loss at iteration 517 is: 6.471257505681129\n",
      "Loss at iteration 518 is: 6.378628210330402\n",
      "Loss at iteration 519 is: 6.287359741675824\n",
      "Loss at iteration 520 is: 6.197431520900459\n",
      "Loss at iteration 521 is: 6.108823290397387\n",
      "Loss at iteration 522 is: 6.02151510858402\n",
      "Loss at iteration 523 is: 5.935487344800416\n",
      "Loss at iteration 524 is: 5.850720674294726\n",
      "Loss at iteration 525 is: 5.76719607329151\n",
      "Loss at iteration 526 is: 5.684894814143199\n",
      "Loss at iteration 527 is: 5.603798460561875\n",
      "Loss at iteration 528 is: 5.523888862931175\n",
      "Loss at iteration 529 is: 5.445148153695324\n",
      "Loss at iteration 530 is: 5.367558742826663\n",
      "Loss at iteration 531 is: 5.291103313367165\n",
      "Loss at iteration 532 is: 5.215764817044945\n",
      "Loss at iteration 533 is: 5.141526469963202\n",
      "Loss at iteration 534 is: 5.068371748361608\n",
      "Loss at iteration 535 is: 4.996284384446739\n",
      "Loss at iteration 536 is: 4.925248362293416\n",
      "Loss at iteration 537 is: 4.855247913812666\n",
      "Loss at iteration 538 is: 4.786267514787319\n",
      "Loss at iteration 539 is: 4.718291880972792\n",
      "Loss at iteration 540 is: 4.6513059642629\n",
      "Loss at iteration 541 is: 4.585294948918731\n",
      "Loss at iteration 542 is: 4.520244247860236\n",
      "Loss at iteration 543 is: 4.4561394990188194\n",
      "Loss at iteration 544 is: 4.392966561750221\n",
      "Loss at iteration 545 is: 4.330711513306946\n",
      "Loss at iteration 546 is: 4.269360645368361\n",
      "Loss at iteration 547 is: 4.208900460628315\n",
      "Loss at iteration 548 is: 4.149317669439308\n",
      "Loss at iteration 549 is: 4.090599186511001\n",
      "Loss at iteration 550 is: 4.032732127663891\n",
      "Loss at iteration 551 is: 3.975703806636104\n",
      "Loss at iteration 552 is: 3.919501731942768\n",
      "Loss at iteration 553 is: 3.8641136037865484\n",
      "Loss at iteration 554 is: 3.8095273110195884\n",
      "Loss at iteration 555 is: 3.7557309281546996\n",
      "Loss at iteration 556 is: 3.702712712425836\n",
      "Loss at iteration 557 is: 3.6504611008969374\n",
      "Loss at iteration 558 is: 3.598964707617411\n",
      "Loss at iteration 559 is: 3.548212320824919\n",
      "Loss at iteration 560 is: 3.4981929001939083\n",
      "Loss at iteration 561 is: 3.4488955741280023\n",
      "Loss at iteration 562 is: 3.4003096370985215\n",
      "Loss at iteration 563 is: 3.3524245470245795\n",
      "Loss at iteration 564 is: 3.3052299226971886\n",
      "Loss at iteration 565 is: 3.258715541244645\n",
      "Loss at iteration 566 is: 3.2128713356399174\n",
      "Loss at iteration 567 is: 3.1676873922477244\n",
      "Loss at iteration 568 is: 3.1231539484124884\n",
      "Loss at iteration 569 is: 3.079261390084869\n",
      "Loss at iteration 570 is: 3.036000249487004\n",
      "Loss at iteration 571 is: 2.9933612028162133\n",
      "Loss at iteration 572 is: 2.9513350679849815\n",
      "Loss at iteration 573 is: 2.9099128023986234\n",
      "Loss at iteration 574 is: 2.8690855007685334\n",
      "Loss at iteration 575 is: 2.828844392960836\n",
      "Loss at iteration 576 is: 2.789180841879994\n",
      "Loss at iteration 577 is: 2.7500863413865897\n",
      "Loss at iteration 578 is: 2.7115525142491776\n",
      "Loss at iteration 579 is: 2.673571110128779\n",
      "Loss at iteration 580 is: 2.6361340035959238\n",
      "Loss at iteration 581 is: 2.5992331921804355\n",
      "Loss at iteration 582 is: 2.562860794451778\n",
      "Loss at iteration 583 is: 2.5270090481311236\n",
      "Loss at iteration 584 is: 2.4916703082332723\n",
      "Loss at iteration 585 is: 2.4568370452388986\n",
      "Loss at iteration 586 is: 2.422501843296355\n",
      "Loss at iteration 587 is: 2.388657398451754\n",
      "Loss at iteration 588 is: 2.3552965169084716\n",
      "Loss at iteration 589 is: 2.3224121133135593\n",
      "Loss at iteration 590 is: 2.2899972090729577\n",
      "Loss at iteration 591 is: 2.258044930692434\n",
      "Loss at iteration 592 is: 2.2265485081461156\n",
      "Loss at iteration 593 is: 2.195501273270839\n",
      "Loss at iteration 594 is: 2.1648966581864046\n",
      "Loss at iteration 595 is: 2.134728193740677\n",
      "Loss at iteration 596 is: 2.104989507980171\n",
      "Loss at iteration 597 is: 2.075674324644875\n",
      "Loss at iteration 598 is: 2.0467764616871262\n",
      "Loss at iteration 599 is: 2.0182898298139964\n",
      "Loss at iteration 600 is: 1.9902084310534998\n",
      "Loss at iteration 601 is: 1.962526357343103\n",
      "Loss at iteration 602 is: 1.9352377891410797\n",
      "Loss at iteration 603 is: 1.9083369940599877\n",
      "Loss at iteration 604 is: 1.8818183255218497\n",
      "Loss at iteration 605 is: 1.8556762214348832\n",
      "Loss at iteration 606 is: 1.8299052028911231\n",
      "Loss at iteration 607 is: 1.8044998728849557\n",
      "Loss at iteration 608 is: 1.7794549150519265\n",
      "Loss at iteration 609 is: 1.7547650924277038\n",
      "Loss at iteration 610 is: 1.7304252462264844\n",
      "Loss at iteration 611 is: 1.7064302946393466\n",
      "Loss at iteration 612 is: 1.6827752316509579\n",
      "Loss at iteration 613 is: 1.6594551258756964\n",
      "Loss at iteration 614 is: 1.6364651194117568\n",
      "Loss at iteration 615 is: 1.6138004267138557\n",
      "Loss at iteration 616 is: 1.5914563334832141\n",
      "Loss at iteration 617 is: 1.5694281955758367\n",
      "Loss at iteration 618 is: 1.547711437927301\n",
      "Loss at iteration 619 is: 1.526301553495089\n",
      "Loss at iteration 620 is: 1.5051941022174922\n",
      "Loss at iteration 621 is: 1.4843847099887464\n",
      "Loss at iteration 622 is: 1.463869067650784\n",
      "Loss at iteration 623 is: 1.4436429300003026\n",
      "Loss at iteration 624 is: 1.4237021148120519\n",
      "Loss at iteration 625 is: 1.4040425018772975\n",
      "Loss at iteration 626 is: 1.3846600320571232\n",
      "Loss at iteration 627 is: 1.365550706351257\n",
      "Loss at iteration 628 is: 1.34671058498102\n",
      "Loss at iteration 629 is: 1.3281357864869237\n",
      "Loss at iteration 630 is: 1.3098224868404462\n",
      "Loss at iteration 631 is: 1.2917669185696028\n",
      "Loss at iteration 632 is: 1.2739653698986806\n",
      "Loss at iteration 633 is: 1.2564141839007326\n",
      "Loss at iteration 634 is: 1.2391097576642365\n",
      "Loss at iteration 635 is: 1.2220485414719275\n",
      "Loss at iteration 636 is: 1.2052270379934515\n",
      "Loss at iteration 637 is: 1.188641801489576\n",
      "Loss at iteration 638 is: 1.1722894370299304\n",
      "Loss at iteration 639 is: 1.156166599722253\n",
      "Loss at iteration 640 is: 1.1402699939538656\n",
      "Loss at iteration 641 is: 1.1245963726452783\n",
      "Loss at iteration 642 is: 1.1091425365149499\n",
      "Loss at iteration 643 is: 1.0939053333560422\n",
      "Loss at iteration 644 is: 1.078881657324037\n",
      "Loss at iteration 645 is: 1.0640684482357987\n",
      "Loss at iteration 646 is: 1.0494626908791649\n",
      "Loss at iteration 647 is: 1.0350614143339314\n",
      "Loss at iteration 648 is: 1.0208616913026074\n",
      "Loss at iteration 649 is: 1.0068606374522\n",
      "Loss at iteration 650 is: 0.9930554107659221\n",
      "Loss at iteration 651 is: 0.9794432109051489\n",
      "Loss at iteration 652 is: 0.9660212785812702\n",
      "Loss at iteration 653 is: 0.9527868949370109\n",
      "Loss at iteration 654 is: 0.9397373809378875\n",
      "Loss at iteration 655 is: 0.9268700967726187\n",
      "Loss at iteration 656 is: 0.9141824412629403\n",
      "Loss at iteration 657 is: 0.901671851282946\n",
      "Loss at iteration 658 is: 0.8893358011868238\n",
      "Loss at iteration 659 is: 0.8771718022459023\n",
      "Loss at iteration 660 is: 0.8651774020941838\n",
      "Loss at iteration 661 is: 0.8533501841825906\n",
      "Loss at iteration 662 is: 0.8416877672415152\n",
      "Loss at iteration 663 is: 0.8301878047517742\n",
      "Loss at iteration 664 is: 0.8188479844237114\n",
      "Loss at iteration 665 is: 0.8076660276843037\n",
      "Loss at iteration 666 is: 0.7966396891721655\n",
      "Loss at iteration 667 is: 0.7857667562405151\n",
      "Loss at iteration 668 is: 0.7750450484674448\n",
      "Loss at iteration 669 is: 0.7644724171742067\n",
      "Loss at iteration 670 is: 0.7540467449504114\n",
      "Loss at iteration 671 is: 0.7437659451870328\n",
      "Loss at iteration 672 is: 0.7336279616161756\n",
      "Loss at iteration 673 is: 0.7236307678580556\n",
      "Loss at iteration 674 is: 0.713772366975171\n",
      "Loss at iteration 675 is: 0.7040507910329501\n",
      "Loss at iteration 676 is: 0.6944641006674375\n",
      "Loss at iteration 677 is: 0.6850103846593706\n",
      "Loss at iteration 678 is: 0.6756877595150834\n",
      "Loss at iteration 679 is: 0.6664943690534837\n",
      "Loss at iteration 680 is: 0.6574283839996051\n",
      "Loss at iteration 681 is: 0.6484880015844344\n",
      "Loss at iteration 682 is: 0.6396714451505562\n",
      "Loss at iteration 683 is: 0.6309769637641817\n",
      "Loss at iteration 684 is: 0.6224028318327927\n",
      "Loss at iteration 685 is: 0.6139473487289593\n",
      "Loss at iteration 686 is: 0.6056088384196157\n",
      "Loss at iteration 687 is: 0.5973856491011179\n",
      "Loss at iteration 688 is: 0.5892761528399842\n",
      "Loss at iteration 689 is: 0.5812787452188167\n",
      "Loss at iteration 690 is: 0.5733918449879292\n",
      "Loss at iteration 691 is: 0.5656138937221333\n",
      "Loss at iteration 692 is: 0.5579433554827715\n",
      "Loss at iteration 693 is: 0.5503787164849138\n",
      "Loss at iteration 694 is: 0.542918484769598\n",
      "Loss at iteration 695 is: 0.5355611898810233\n",
      "Loss at iteration 696 is: 0.528305382548811\n",
      "Loss at iteration 697 is: 0.5211496343748594\n",
      "Loss at iteration 698 is: 0.5140925375251442\n",
      "Loss at iteration 699 is: 0.5071327044260994\n",
      "Loss at iteration 700 is: 0.500268767465617\n",
      "Loss at iteration 701 is: 0.4934993786987257\n",
      "Loss at iteration 702 is: 0.486823209557358\n",
      "Loss at iteration 703 is: 0.4802389505649942\n",
      "Loss at iteration 704 is: 0.4737453110553855\n",
      "Loss at iteration 705 is: 0.46734101889529467\n",
      "Loss at iteration 706 is: 0.461024820212091\n",
      "Loss at iteration 707 is: 0.4547954791246628\n",
      "Loss at iteration 708 is: 0.44865177747911167\n",
      "Loss at iteration 709 is: 0.4425925145879096\n",
      "Loss at iteration 710 is: 0.4366165069733346\n",
      "Loss at iteration 711 is: 0.4307225881146587\n",
      "Loss at iteration 712 is: 0.4249096081990812\n",
      "Loss at iteration 713 is: 0.41917643387653386\n",
      "Loss at iteration 714 is: 0.4135219480181492\n",
      "Loss at iteration 715 is: 0.40794504947831745\n",
      "Loss at iteration 716 is: 0.40244465286046804\n",
      "Loss at iteration 717 is: 0.3970196882861279\n",
      "Loss at iteration 718 is: 0.39166910116772047\n",
      "Loss at iteration 719 is: 0.3863918519847387\n",
      "Loss at iteration 720 is: 0.3811869160629545\n",
      "Loss at iteration 721 is: 0.3760532833574955\n",
      "Loss at iteration 722 is: 0.3709899582387384\n",
      "Loss at iteration 723 is: 0.36599595928162243\n",
      "Loss at iteration 724 is: 0.361070319058018\n",
      "Loss at iteration 725 is: 0.3562120839323548\n",
      "Loss at iteration 726 is: 0.3514203138601587\n",
      "Loss at iteration 727 is: 0.34669408218976494\n",
      "Loss at iteration 728 is: 0.34203247546676063\n",
      "Loss at iteration 729 is: 0.3374345932417182\n",
      "Loss at iteration 730 is: 0.33289954788040244\n",
      "Loss at iteration 731 is: 0.3284264643771544\n",
      "Loss at iteration 732 is: 0.3240144801708889\n",
      "Loss at iteration 733 is: 0.31966274496384217\n",
      "Loss at iteration 734 is: 0.31537042054311726\n",
      "Loss at iteration 735 is: 0.31113668060486666\n",
      "Loss at iteration 736 is: 0.3069607105809905\n",
      "Loss at iteration 737 is: 0.3028417074686389\n",
      "Loss at iteration 738 is: 0.29877887966199346\n",
      "Loss at iteration 739 is: 0.2947714467867892\n",
      "Loss at iteration 740 is: 0.2908186395372033\n",
      "Loss at iteration 741 is: 0.2869196995151335\n",
      "Loss at iteration 742 is: 0.2830738790719418\n",
      "Loss at iteration 743 is: 0.2792804411525196\n",
      "Loss at iteration 744 is: 0.27553865914175946\n",
      "Loss at iteration 745 is: 0.27184781671303604\n",
      "Loss at iteration 746 is: 0.2682072076794199\n",
      "Loss at iteration 747 is: 0.26461613584652044\n",
      "Loss at iteration 748 is: 0.26107391486807274\n",
      "Loss at iteration 749 is: 0.257579868103201\n",
      "Loss at iteration 750 is: 0.2541333284761933\n",
      "Loss at iteration 751 is: 0.25073363833802487\n",
      "Loss at iteration 752 is: 0.24738014933018185\n",
      "Loss at iteration 753 is: 0.2440722222503442\n",
      "Loss at iteration 754 is: 0.24080922692013795\n",
      "Loss at iteration 755 is: 0.23759054205485355\n",
      "Loss at iteration 756 is: 0.2344155551350572\n",
      "Loss at iteration 757 is: 0.23128366228007782\n",
      "Loss at iteration 758 is: 0.22819426812343274\n",
      "Loss at iteration 759 is: 0.2251467856900901\n",
      "Loss at iteration 760 is: 0.22214063627543235\n",
      "Loss at iteration 761 is: 0.21917524932618512\n",
      "Loss at iteration 762 is: 0.21625006232298286\n",
      "Loss at iteration 763 is: 0.21336452066467185\n",
      "Loss at iteration 764 is: 0.21051807755439406\n",
      "Loss at iteration 765 is: 0.2077101938872714\n",
      "Loss at iteration 766 is: 0.20494033813980292\n",
      "Loss at iteration 767 is: 0.2022079862608112\n",
      "Loss at iteration 768 is: 0.19951262156416336\n",
      "Loss at iteration 769 is: 0.1968537346228626\n",
      "Loss at iteration 770 is: 0.19423082316483362\n",
      "Loss at iteration 771 is: 0.19164339197022182\n",
      "Loss at iteration 772 is: 0.18909095277017157\n",
      "Loss at iteration 773 is: 0.18657302414708304\n",
      "Loss at iteration 774 is: 0.18408913143641487\n",
      "Loss at iteration 775 is: 0.18163880662982537\n",
      "Loss at iteration 776 is: 0.17922158827982518\n",
      "Loss at iteration 777 is: 0.17683702140577462\n",
      "Loss at iteration 778 is: 0.17448465740122912\n",
      "Loss at iteration 779 is: 0.17216405394280562\n",
      "Loss at iteration 780 is: 0.1698747749001607\n",
      "Loss at iteration 781 is: 0.16761639024740144\n",
      "Loss at iteration 782 is: 0.16538847597593462\n",
      "Loss at iteration 783 is: 0.16319061400820434\n",
      "Loss at iteration 784 is: 0.16102239211314445\n",
      "Loss at iteration 785 is: 0.15888340382258265\n",
      "Loss at iteration 786 is: 0.15677324834894674\n",
      "Loss at iteration 787 is: 0.1546915305041387\n",
      "Loss at iteration 788 is: 0.15263786061970244\n",
      "Loss at iteration 789 is: 0.15061185446802622\n",
      "Loss at iteration 790 is: 0.14861313318476027\n",
      "Loss at iteration 791 is: 0.14664132319237222\n",
      "Loss at iteration 792 is: 0.1446960561248019\n",
      "Loss at iteration 793 is: 0.14277696875322748\n",
      "Loss at iteration 794 is: 0.14088370291286834\n",
      "Loss at iteration 795 is: 0.13901590543094508\n",
      "Loss at iteration 796 is: 0.13717322805561047\n",
      "Loss at iteration 797 is: 0.13535532738589418\n",
      "Loss at iteration 798 is: 0.13356186480282942\n",
      "Loss at iteration 799 is: 0.13179250640135157\n",
      "Loss at iteration 800 is: 0.13004692292334963\n",
      "Loss at iteration 801 is: 0.12832478969169514\n",
      "Loss at iteration 802 is: 0.12662578654506637\n",
      "Loss at iteration 803 is: 0.12494959777392396\n",
      "Loss at iteration 804 is: 0.1232959120572925\n",
      "Loss at iteration 805 is: 0.12166442240051487\n",
      "Loss at iteration 806 is: 0.12005482607384171\n",
      "Loss at iteration 807 is: 0.11846682455203497\n",
      "Loss at iteration 808 is: 0.11690012345467193\n",
      "Loss at iteration 809 is: 0.11535443248752177\n",
      "Loss at iteration 810 is: 0.11382946538455302\n",
      "Loss at iteration 811 is: 0.11232493985099676\n",
      "Loss at iteration 812 is: 0.11084057750706053\n",
      "Loss at iteration 813 is: 0.1093761038325746\n",
      "Loss at iteration 814 is: 0.1079312481123352\n",
      "Loss at iteration 815 is: 0.10650574338235658\n",
      "Loss at iteration 816 is: 0.10509932637678174\n",
      "Loss at iteration 817 is: 0.10371173747566541\n",
      "Loss at iteration 818 is: 0.10234272065342433\n",
      "Loss at iteration 819 is: 0.10099202342811371\n",
      "Loss at iteration 820 is: 0.0996593968113664\n",
      "Loss at iteration 821 is: 0.09834459525907996\n",
      "Loss at iteration 822 is: 0.09704737662281979\n",
      "Loss at iteration 823 is: 0.09576750210192977\n",
      "Loss at iteration 824 is: 0.09450473619634958\n",
      "Loss at iteration 825 is: 0.09325884666001623\n",
      "Loss at iteration 826 is: 0.09202960445510797\n",
      "Loss at iteration 827 is: 0.09081678370672404\n",
      "Loss at iteration 828 is: 0.08962016165846934\n",
      "Loss at iteration 829 is: 0.08843951862847751\n",
      "Loss at iteration 830 is: 0.08727463796611876\n",
      "Loss at iteration 831 is: 0.08612530600943928\n",
      "Loss at iteration 832 is: 0.08499131204300195\n",
      "Loss at iteration 833 is: 0.08387244825659748\n",
      "Loss at iteration 834 is: 0.08276850970428669\n",
      "Loss at iteration 835 is: 0.08167929426418477\n",
      "Loss at iteration 836 is: 0.08060460259884167\n",
      "Loss at iteration 837 is: 0.07954423811606619\n",
      "Loss at iteration 838 is: 0.07849800693041989\n",
      "Loss at iteration 839 is: 0.07746571782525767\n",
      "Loss at iteration 840 is: 0.07644718221518931\n",
      "Loss at iteration 841 is: 0.07544221410929416\n",
      "Loss at iteration 842 is: 0.07445063007465168\n",
      "Loss at iteration 843 is: 0.07347224920050272\n",
      "Loss at iteration 844 is: 0.07250689306294325\n",
      "Loss at iteration 845 is: 0.07155438569004724\n",
      "Loss at iteration 846 is: 0.07061455352752705\n",
      "Loss at iteration 847 is: 0.06968722540493558\n",
      "Loss at iteration 848 is: 0.06877223250220854\n",
      "Loss at iteration 849 is: 0.0678694083168683\n",
      "Loss at iteration 850 is: 0.06697858863156353\n",
      "Loss at iteration 851 is: 0.0660996114821242\n",
      "Loss at iteration 852 is: 0.06523231712603525\n",
      "Loss at iteration 853 is: 0.06437654801143206\n",
      "Loss at iteration 854 is: 0.06353214874649293\n",
      "Loss at iteration 855 is: 0.06269896606918836\n",
      "Loss at iteration 856 is: 0.06187684881768424\n",
      "Loss at iteration 857 is: 0.06106564790089303\n",
      "Loss at iteration 858 is: 0.060265216269657945\n",
      "Loss at iteration 859 is: 0.05947540888822908\n",
      "Loss at iteration 860 is: 0.05869608270619632\n",
      "Loss at iteration 861 is: 0.057927096630818735\n",
      "Loss at iteration 862 is: 0.05716831149972076\n",
      "Loss at iteration 863 is: 0.056419590054008525\n",
      "Loss at iteration 864 is: 0.055680796911726706\n",
      "Loss at iteration 865 is: 0.05495179854176608\n",
      "Loss at iteration 866 is: 0.05423246323806476\n",
      "Loss at iteration 867 is: 0.05352266109421538\n",
      "Loss at iteration 868 is: 0.052822263978404525\n",
      "Loss at iteration 869 is: 0.05213114550877862\n",
      "Loss at iteration 870 is: 0.05144918102904554\n",
      "Loss at iteration 871 is: 0.050776247584559064\n",
      "Loss at iteration 872 is: 0.05011222389858766\n",
      "Loss at iteration 873 is: 0.04945699034906574\n",
      "Loss at iteration 874 is: 0.048810428945602585\n",
      "Loss at iteration 875 is: 0.04817242330677939\n",
      "Loss at iteration 876 is: 0.0475428586378612\n",
      "Loss at iteration 877 is: 0.04692162170877048\n",
      "Loss at iteration 878 is: 0.04630860083235214\n",
      "Loss at iteration 879 is: 0.045703685842982664\n",
      "Loss at iteration 880 is: 0.04510676807551849\n",
      "Loss at iteration 881 is: 0.0445177403444208\n",
      "Loss at iteration 882 is: 0.0439364969233059\n",
      "Loss at iteration 883 is: 0.043362933524689104\n",
      "Loss at iteration 884 is: 0.042796947280097856\n",
      "Loss at iteration 885 is: 0.042238436720388364\n",
      "Loss at iteration 886 is: 0.04168730175639424\n",
      "Loss at iteration 887 is: 0.04114344365981857\n",
      "Loss at iteration 888 is: 0.04060676504440134\n",
      "Loss at iteration 889 is: 0.04007716984738184\n",
      "Loss at iteration 890 is: 0.03955456331116294\n",
      "Loss at iteration 891 is: 0.03903885196528627\n",
      "Loss at iteration 892 is: 0.03852994360866988\n",
      "Loss at iteration 893 is: 0.03802774729200623\n",
      "Loss at iteration 894 is: 0.037532173300535064\n",
      "Loss at iteration 895 is: 0.03704313313697308\n",
      "Loss at iteration 896 is: 0.03656053950467612\n",
      "Loss at iteration 897 is: 0.03608430629111915\n",
      "Loss at iteration 898 is: 0.03561434855154927\n",
      "Loss at iteration 899 is: 0.03515058249283484\n",
      "Loss at iteration 900 is: 0.034692925457618276\n",
      "Loss at iteration 901 is: 0.03424129590867598\n",
      "Loss at iteration 902 is: 0.033795613413433075\n",
      "Loss at iteration 903 is: 0.03335579862878376\n",
      "Loss at iteration 904 is: 0.03292177328606225\n",
      "Loss at iteration 905 is: 0.032493460176240746\n",
      "Loss at iteration 906 is: 0.03207078313536535\n",
      "Loss at iteration 907 is: 0.03165366703014661\n",
      "Loss at iteration 908 is: 0.03124203774378915\n",
      "Loss at iteration 909 is: 0.03083582216200761\n",
      "Loss at iteration 910 is: 0.0304349481592342\n",
      "Loss at iteration 911 is: 0.030039344585020344\n",
      "Loss at iteration 912 is: 0.029648941250649968\n",
      "Loss at iteration 913 is: 0.029263668915908078\n",
      "Loss at iteration 914 is: 0.028883459276041728\n",
      "Loss at iteration 915 is: 0.02850824494894268\n",
      "Loss at iteration 916 is: 0.028137959462432242\n",
      "Loss at iteration 917 is: 0.027772537241813066\n",
      "Loss at iteration 918 is: 0.02741191359753093\n",
      "Loss at iteration 919 is: 0.027056024713034012\n",
      "Loss at iteration 920 is: 0.02670480763276538\n",
      "Loss at iteration 921 is: 0.026358200250430827\n",
      "Loss at iteration 922 is: 0.026016141297286043\n",
      "Loss at iteration 923 is: 0.02567857033067603\n",
      "Loss at iteration 924 is: 0.025345427722731285\n",
      "Loss at iteration 925 is: 0.025016654649166914\n",
      "Loss at iteration 926 is: 0.02469219307834187\n",
      "Loss at iteration 927 is: 0.02437198576033694\n",
      "Loss at iteration 928 is: 0.02405597621627697\n",
      "Loss at iteration 929 is: 0.023744108727799165\n",
      "Loss at iteration 930 is: 0.023436328326633546\n",
      "Loss at iteration 931 is: 0.023132580784322187\n",
      "Loss at iteration 932 is: 0.022832812602140786\n",
      "Loss at iteration 933 is: 0.022536971001076933\n",
      "Loss at iteration 934 is: 0.02224500391203527\n",
      "Loss at iteration 935 is: 0.02195685996610763\n",
      "Loss at iteration 936 is: 0.021672488485026106\n",
      "Loss at iteration 937 is: 0.02139183947169124\n",
      "Loss at iteration 938 is: 0.02111486360093941\n",
      "Loss at iteration 939 is: 0.020841512210302504\n",
      "Loss at iteration 940 is: 0.020571737290995127\n",
      "Loss at iteration 941 is: 0.020305491478990155\n",
      "Loss at iteration 942 is: 0.0200427280462319\n",
      "Loss at iteration 943 is: 0.019783400891950773\n",
      "Loss at iteration 944 is: 0.01952746453408759\n",
      "Loss at iteration 945 is: 0.019274874100924762\n",
      "Loss at iteration 946 is: 0.01902558532269616\n",
      "Loss at iteration 947 is: 0.0187795545234382\n",
      "Loss at iteration 948 is: 0.018536738612866796\n",
      "Loss at iteration 949 is: 0.0182970950784273\n",
      "Loss at iteration 950 is: 0.018060581977402228\n",
      "Loss at iteration 951 is: 0.017827157929181832\n",
      "Loss at iteration 952 is: 0.01759678210759288\n",
      "Loss at iteration 953 is: 0.017369414233377237\n",
      "Loss at iteration 954 is: 0.01714501456670945\n",
      "Loss at iteration 955 is: 0.016923543899923538\n",
      "Loss at iteration 956 is: 0.016704963550237897\n",
      "Loss at iteration 957 is: 0.016489235352615\n",
      "Loss at iteration 958 is: 0.016276321652753382\n",
      "Loss at iteration 959 is: 0.01606618530012398\n",
      "Loss at iteration 960 is: 0.015858789641142186\n",
      "Loss at iteration 961 is: 0.015654098512424913\n",
      "Loss at iteration 962 is: 0.01545207623411627\n",
      "Loss at iteration 963 is: 0.015252687603330928\n",
      "Loss at iteration 964 is: 0.015055897887688383\n",
      "Loss at iteration 965 is: 0.014861672818934607\n",
      "Loss at iteration 966 is: 0.014669978586636882\n",
      "Loss at iteration 967 is: 0.01448078183196514\n",
      "Loss at iteration 968 is: 0.014294049641594114\n",
      "Loss at iteration 969 is: 0.014109749541648163\n",
      "Loss at iteration 970 is: 0.013927849491752516\n",
      "Loss at iteration 971 is: 0.013748317879150884\n",
      "Loss at iteration 972 is: 0.013571123512934543\n",
      "Loss at iteration 973 is: 0.013396235618311289\n",
      "Loss at iteration 974 is: 0.013223623830965711\n",
      "Loss at iteration 975 is: 0.01305325819152801\n",
      "Loss at iteration 976 is: 0.012885109140078163\n",
      "Loss at iteration 977 is: 0.01271914751073978\n",
      "Loss at iteration 978 is: 0.012555344526363504\n",
      "Loss at iteration 979 is: 0.01239367179324033\n",
      "Loss at iteration 980 is: 0.012234101295968497\n",
      "Loss at iteration 981 is: 0.012076605392282485\n",
      "Loss at iteration 982 is: 0.011921156808057446\n",
      "Loss at iteration 983 is: 0.011767728632298333\n",
      "Loss at iteration 984 is: 0.011616294312271729\n",
      "Loss at iteration 985 is: 0.011466827648633188\n",
      "Loss at iteration 986 is: 0.011319302790669568\n",
      "Loss at iteration 987 is: 0.011173694231609806\n",
      "Loss at iteration 988 is: 0.011029976803956277\n",
      "Loss at iteration 989 is: 0.01088812567491319\n",
      "Loss at iteration 990 is: 0.01074811634188019\n",
      "Loss at iteration 991 is: 0.0106099246280082\n",
      "Loss at iteration 992 is: 0.010473526677776502\n",
      "Loss at iteration 993 is: 0.010338898952687707\n",
      "Loss at iteration 994 is: 0.010206018226987182\n",
      "Loss at iteration 995 is: 0.010074861583439631\n",
      "Loss at iteration 996 is: 0.00994540640919097\n",
      "Loss at iteration 997 is: 0.009817630391648397\n",
      "Loss at iteration 998 is: 0.00969151151445491\n",
      "Loss at iteration 999 is: 0.009567028053494363\n",
      "Loss at iteration 1000 is: 0.009444158572942812\n",
      "Loss at iteration 1001 is: 0.009322881921418745\n",
      "Loss at iteration 1002 is: 0.009203177228135668\n",
      "Loss at iteration 1003 is: 0.009085023899129635\n",
      "Loss at iteration 1004 is: 0.008968401613528446\n",
      "Loss at iteration 1005 is: 0.008853290319914884\n",
      "Loss at iteration 1006 is: 0.008739670232653955\n",
      "Loss at iteration 1007 is: 0.008627521828367495\n",
      "Loss at iteration 1008 is: 0.008516825842368783\n",
      "Loss at iteration 1009 is: 0.008407563265228773\n",
      "Loss at iteration 1010 is: 0.008299715339310157\n",
      "Loss at iteration 1011 is: 0.008193263555407837\n",
      "Loss at iteration 1012 is: 0.008088189649408162\n",
      "Loss at iteration 1013 is: 0.007984475599000663\n",
      "Loss at iteration 1014 is: 0.007882103620428411\n",
      "Loss at iteration 1015 is: 0.00778105616529418\n",
      "Loss at iteration 1016 is: 0.007681315917390952\n",
      "Loss at iteration 1017 is: 0.007582865789606106\n",
      "Loss at iteration 1018 is: 0.0074856889208355145\n",
      "Loss at iteration 1019 is: 0.007389768672954131\n",
      "Loss at iteration 1020 is: 0.0072950886278398425\n",
      "Loss at iteration 1021 is: 0.007201632584409387\n",
      "Loss at iteration 1022 is: 0.007109384555713981\n",
      "Loss at iteration 1023 is: 0.007018328766089531\n",
      "Loss at iteration 1024 is: 0.006928449648296069\n",
      "Loss at iteration 1025 is: 0.006839731840750229\n",
      "Loss at iteration 1026 is: 0.0067521601847664175\n",
      "Loss at iteration 1027 is: 0.006665719721840421\n",
      "Loss at iteration 1028 is: 0.006580395690961051\n",
      "Loss at iteration 1029 is: 0.00649617352598979\n",
      "Loss at iteration 1030 is: 0.006413038853035222\n",
      "Loss at iteration 1031 is: 0.006330977487888644\n",
      "Loss at iteration 1032 is: 0.0062499754334868415\n",
      "Loss at iteration 1033 is: 0.006170018877416118\n",
      "Loss at iteration 1034 is: 0.006091094189435731\n",
      "Loss at iteration 1035 is: 0.006013187919046546\n",
      "Loss at iteration 1036 is: 0.005936286793092241\n",
      "Loss at iteration 1037 is: 0.00586037771339235\n",
      "Loss at iteration 1038 is: 0.005785447754402458\n",
      "Loss at iteration 1039 is: 0.005711484160899397\n",
      "Loss at iteration 1040 is: 0.005638474345729947\n",
      "Loss at iteration 1041 is: 0.005566405887543772\n",
      "Loss at iteration 1042 is: 0.005495266528606985\n",
      "Loss at iteration 1043 is: 0.005425044172588897\n",
      "Loss at iteration 1044 is: 0.005355726882436156\n",
      "Loss at iteration 1045 is: 0.005287302878236882\n",
      "Loss at iteration 1046 is: 0.005219760535116839\n",
      "Loss at iteration 1047 is: 0.005153088381191049\n",
      "Loss at iteration 1048 is: 0.005087275095518443\n",
      "Loss at iteration 1049 is: 0.005022309506073761\n",
      "Loss at iteration 1050 is: 0.004958180587795067\n",
      "Loss at iteration 1051 is: 0.0048948774605947435\n",
      "Loss at iteration 1052 is: 0.004832389387450512\n",
      "Loss at iteration 1053 is: 0.004770705772491933\n",
      "Loss at iteration 1054 is: 0.004709816159122402\n",
      "Loss at iteration 1055 is: 0.004649710228163205\n",
      "Loss at iteration 1056 is: 0.004590377796026171\n",
      "Loss at iteration 1057 is: 0.004531808812914948\n",
      "Loss at iteration 1058 is: 0.004473993361038008\n",
      "Loss at iteration 1059 is: 0.004416921652856556\n",
      "Loss at iteration 1060 is: 0.0043605840293521585\n",
      "Loss at iteration 1061 is: 0.004304970958315868\n",
      "Loss at iteration 1062 is: 0.004250073032670431\n",
      "Loss at iteration 1063 is: 0.00419588096879301\n",
      "Loss at iteration 1064 is: 0.004142385604891766\n",
      "Loss at iteration 1065 is: 0.004089577899371326\n",
      "Loss at iteration 1066 is: 0.004037448929252929\n",
      "Loss at iteration 1067 is: 0.00398598988858265\n",
      "Loss at iteration 1068 is: 0.003935192086889313\n",
      "Loss at iteration 1069 is: 0.0038850469476474888\n",
      "Loss at iteration 1070 is: 0.003835546006763742\n",
      "Loss at iteration 1071 is: 0.0037866809110900673\n",
      "Loss at iteration 1072 is: 0.00373844341694403\n",
      "Loss at iteration 1073 is: 0.0036908253886624364\n",
      "Loss at iteration 1074 is: 0.003643818797170446\n",
      "Loss at iteration 1075 is: 0.0035974157185586523\n",
      "Loss at iteration 1076 is: 0.0035516083326998854\n",
      "Loss at iteration 1077 is: 0.0035063889218696926\n",
      "Loss at iteration 1078 is: 0.0034617498693907205\n",
      "Loss at iteration 1079 is: 0.0034176836582820625\n",
      "Loss at iteration 1080 is: 0.0033741828699588674\n",
      "Loss at iteration 1081 is: 0.003331240182912313\n",
      "Loss at iteration 1082 is: 0.0032888483714332162\n",
      "Loss at iteration 1083 is: 0.0032470003043403917\n",
      "Loss at iteration 1084 is: 0.0032056889437274225\n",
      "Loss at iteration 1085 is: 0.0031649073437329312\n",
      "Loss at iteration 1086 is: 0.0031246486493162187\n",
      "Loss at iteration 1087 is: 0.0030849060950654704\n",
      "Loss at iteration 1088 is: 0.0030456730039972774\n",
      "Loss at iteration 1089 is: 0.003006942786405362\n",
      "Loss at iteration 1090 is: 0.002968708938689192\n",
      "Loss at iteration 1091 is: 0.002930965042227029\n",
      "Loss at iteration 1092 is: 0.0028937047622492875\n",
      "Loss at iteration 1093 is: 0.002856921846726767\n",
      "Loss at iteration 1094 is: 0.002820610125281468\n",
      "Loss at iteration 1095 is: 0.0027847635081068405\n",
      "Loss at iteration 1096 is: 0.0027493759849070098\n",
      "Loss at iteration 1097 is: 0.0027144416238368187\n",
      "Loss at iteration 1098 is: 0.0026799545704757092\n",
      "Loss at iteration 1099 is: 0.002645909046801935\n",
      "Loss at iteration 1100 is: 0.002612299350181769\n",
      "Loss at iteration 1101 is: 0.0025791198523794326\n",
      "Loss at iteration 1102 is: 0.0025463649985733024\n",
      "Loss at iteration 1103 is: 0.0025140293063835007\n",
      "Loss at iteration 1104 is: 0.0024821073649190376\n",
      "Loss at iteration 1105 is: 0.00245059383384277\n",
      "Loss at iteration 1106 is: 0.0024194834424250793\n",
      "Loss at iteration 1107 is: 0.0023887709886413313\n",
      "Loss at iteration 1108 is: 0.002358451338254114\n",
      "Loss at iteration 1109 is: 0.0023285194239335344\n",
      "Loss at iteration 1110 is: 0.002298970244356333\n",
      "Loss at iteration 1111 is: 0.0022697988633582616\n",
      "Loss at iteration 1112 is: 0.002241000409057483\n",
      "Loss at iteration 1113 is: 0.0022125700730207675\n",
      "Loss at iteration 1114 is: 0.0021845031094194127\n",
      "Loss at iteration 1115 is: 0.0021567948342069232\n",
      "Loss at iteration 1116 is: 0.0021294406243083136\n",
      "Loss at iteration 1117 is: 0.0021024359168213495\n",
      "Loss at iteration 1118 is: 0.0020757762082107235\n",
      "Loss at iteration 1119 is: 0.002049457053541971\n",
      "Loss at iteration 1120 is: 0.0020234740657015847\n",
      "Loss at iteration 1121 is: 0.0019978229146414327\n",
      "Loss at iteration 1122 is: 0.001972499326623819\n",
      "Loss at iteration 1123 is: 0.0019474990834865147\n",
      "Loss at iteration 1124 is: 0.0019228180219069062\n",
      "Loss at iteration 1125 is: 0.0018984520326840164\n",
      "Loss at iteration 1126 is: 0.0018743970600262404\n",
      "Loss at iteration 1127 is: 0.0018506491008526116\n",
      "Loss at iteration 1128 is: 0.001827204204092595\n",
      "Loss at iteration 1129 is: 0.0018040584700138678\n",
      "Loss at iteration 1130 is: 0.001781208049535984\n",
      "Loss at iteration 1131 is: 0.001758649143579633\n",
      "Loss at iteration 1132 is: 0.001736378002392258\n",
      "Loss at iteration 1133 is: 0.0017143909249204199\n",
      "Loss at iteration 1134 is: 0.0016926842581514495\n",
      "Loss at iteration 1135 is: 0.0016712543964975588\n",
      "Loss at iteration 1136 is: 0.0016500977811682673\n",
      "Loss at iteration 1137 is: 0.0016292108995532304\n",
      "Loss at iteration 1138 is: 0.0016085902846251152\n",
      "Loss at iteration 1139 is: 0.0015882325143306572\n",
      "Loss at iteration 1140 is: 0.001568134211008617\n",
      "Loss at iteration 1141 is: 0.0015482920408068914\n",
      "Loss at iteration 1142 is: 0.0015287027131070188\n",
      "Loss at iteration 1143 is: 0.0015093629799594055\n",
      "Loss at iteration 1144 is: 0.001490269635520689\n",
      "Loss at iteration 1145 is: 0.001471419515504634\n",
      "Loss at iteration 1146 is: 0.0014528094966367864\n",
      "Loss at iteration 1147 is: 0.0014344364961185678\n",
      "Loss at iteration 1148 is: 0.001416297471097611\n",
      "Loss at iteration 1149 is: 0.0013983894181423203\n",
      "Loss at iteration 1150 is: 0.001380709372724765\n",
      "Loss at iteration 1151 is: 0.001363254408719285\n",
      "Loss at iteration 1152 is: 0.001346021637891563\n",
      "Loss at iteration 1153 is: 0.001329008209400748\n",
      "Loss at iteration 1154 is: 0.0013122113093266563\n",
      "Loss at iteration 1155 is: 0.0012956281601646268\n",
      "Loss at iteration 1156 is: 0.0012792560203662502\n",
      "Loss at iteration 1157 is: 0.0012630921838614109\n",
      "Loss at iteration 1158 is: 0.0012471339795925207\n",
      "Loss at iteration 1159 is: 0.0012313787710666743\n",
      "Loss at iteration 1160 is: 0.0012158239558916588\n",
      "Loss at iteration 1161 is: 0.0012004669653404617\n",
      "Loss at iteration 1162 is: 0.0011853052639043868\n",
      "Loss at iteration 1163 is: 0.0011703363488611454\n",
      "Loss at iteration 1164 is: 0.0011555577498514962\n",
      "Loss at iteration 1165 is: 0.0011409670284448462\n",
      "Loss at iteration 1166 is: 0.0011265617777370888\n",
      "Loss at iteration 1167 is: 0.001112339621927635\n",
      "Loss at iteration 1168 is: 0.0010982982159182795\n",
      "Loss at iteration 1169 is: 0.0010844352449105373\n",
      "Loss at iteration 1170 is: 0.0010707484240140353\n",
      "Loss at iteration 1171 is: 0.0010572354978484928\n",
      "Loss at iteration 1172 is: 0.0010438942401682985\n",
      "Loss at iteration 1173 is: 0.0010307224534758298\n",
      "Loss at iteration 1174 is: 0.0010177179686461897\n",
      "Loss at iteration 1175 is: 0.0010048786445656251\n",
      "Loss at iteration 1176 is: 0.0009922023677521805\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# N = nmero de ejemplos, D_in = dimensionalidad input, D_out = dimensionalidad output.\n",
    "N, D_in, D_out = 64, 1000, 1\n",
    "\n",
    "# Datos de entrada y salida aleatorios (que relacin tiene esto con el sobreajuste?)\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Pesos iniciales aleatorios para el Perceptrn\n",
    "w = np.random.randn(D_in, D_out)\n",
    "\n",
    "learning_rate = 1e-5\n",
    "loss = 1e6\n",
    "iteration = 1\n",
    "while loss > 1e-3:\n",
    "    y_pred = x.dot(w)\n",
    "    loss = 0.5*np.square(y_pred - y).sum()\n",
    "    print(\"Loss at iteration %d is:\" % iteration, loss)\n",
    "\n",
    "    grad_y_pred = y_pred - y\n",
    "    grad_w = x.T.dot(grad_y_pred)\n",
    "    w -= learning_rate * grad_w\n",
    "    iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
