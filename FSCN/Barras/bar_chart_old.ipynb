{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nucontreras/artificial-intelligence-scripts/blob/main/FSCN/Barras/bar_chart_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W64CYScwd13"
      },
      "source": [
        "<b><FONT size=\"8\" color='264653'>Audiographics Project: sonification for the accessibility of quantitative information in graphic format </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSbhuvYwd8m"
      },
      "source": [
        "><b><FONT size=\"3\" color='DimGray'> Sonification for the accessibility of quantitative information in graphic format is part of the research line in Technology and Care of the Millennium Institute for Care Research ([MICARE](https://www.micare.cl/)). The objective of this project is to implement a tool for the transformation of quantitative information presented in visual form into audio to facilitate access to visually handicapped people, using sonification techniques and image analysis through artificial intelligence. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4YTrjY5cj8"
      },
      "source": [
        "><b><FONT size=\"3\" color='DimGray'> This file contains the processing, treatment and tests of a neural network used to filter bar chart images. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hutlz3dT4NCx"
      },
      "source": [
        "><b><FONT size=\"3\" color='SlateGray'> Code edited from an old code made in an iPre. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hYGDE_wtAH"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Connection to Google Drive </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7OeQ4PzvKQh",
        "outputId": "f32951c0-340a-4eb4-e9f3-10e222c2de9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/.shortcut-targets-by-id/1BQNCMYEG1Xd_TAcD5txHIHbOaJiFKKWE/AudioGraphs/Codigos y BD anteriores\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd 'gdrive/MyDrive/AudioGraphs/Codigos y BD anteriores'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7UcfBVI68oG",
        "outputId": "9fbeef10-dd52-4aff-d941-990837bf4f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barras\tLineas\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE02A7t4F6kh"
      },
      "source": [
        "<b><FONT size=\"4\" color='619b8a'>Path to bar chart images dataset  </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jWf-E9qRF6sX"
      },
      "outputs": [],
      "source": [
        "path_bar_chart_db = 'Barras/models/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7q5gU9-xX0v"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Import of packages </FONT>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PGt3yRfFxXOo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from random import shuffle, seed\n",
        "\n",
        "# Data processing and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# AI models\n",
        "import tensorflow as tf\n",
        "from keras.utils import Sequence, plot_model\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "seed(420)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZyNlhEMJNod"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Generator </FONT>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pootz8NeJWb5"
      },
      "source": [
        "><b><FONT size=\"3\" color='DimGray'> Creation of the generator to pass the images to the model for training it. </FONT>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "67Qx_TEwxXV6"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, directory, targets_dir, color_mode=\"grayscale\", subdirs=False, batch_size=32, dim=(256, 256), n_channels=1, shuffle=True):\n",
        "        self.x = self.read_directory(directory, subdirs)\n",
        "        self.directory = directory\n",
        "        self.targets_dir = targets_dir\n",
        "        self.len = len(self.x)\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "    def read_directory(self, directory, subdirs):\n",
        "        if not subdirs:\n",
        "            return os.listdir(directory)\n",
        "        raise FileExistsError\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.len // self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch = self.x[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        x, y = self.read_images(batch)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            shuffle(self.x)\n",
        "\n",
        "    def read_images(self, batch):\n",
        "        # Inicialización de datos\n",
        "        # X e y son de igual dimensión ya que ambos son imágenes\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        x, y = np.empty((self.batch_size, *self.dim, self.n_channels)), np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "\n",
        "        # Generación de data\n",
        "        for i, name in enumerate(batch):\n",
        "            path = self.directory + \"/\" + name\n",
        "            img = tf.keras.utils.load_img(path, target_size=(256, 256), color_mode = \"grayscale\")\n",
        "            img = tf.keras.utils.img_to_array(img)\n",
        "            x[i] = img / 255\n",
        "\n",
        "            target_path = self.targets_dir + \"/\" + name\n",
        "            target_img = tf.keras.utils.load_img(target_path, target_size=(256, 256), color_mode = \"grayscale\")\n",
        "            target_img = tf.keras.utils.img_to_array(target_img)\n",
        "            y[i] = target_img / 255\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu5Dlqr0KGvS"
      },
      "source": [
        "Creation of generators for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wodw7oeYxXa_"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_path_x = path_bar_chart_db + \"dataset/segmentation-2/train/color\"\n",
        "train_path_y = path_bar_chart_db + \"dataset/segmentation-2/train/segmented\"\n",
        "\n",
        "test_path_x = path_bar_chart_db + \"dataset/segmentation-2/test/color\"\n",
        "test_path_y = path_bar_chart_db + \"dataset/segmentation-2/test/segmented\"\n",
        "\n",
        "train_gen = DataGenerator(train_path_x, train_path_y, batch_size=BATCH_SIZE)\n",
        "test_gen = DataGenerator(test_path_x, test_path_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "85NgsErVKIAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f42686d-51ce-433a-88d3-fae5484d6047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Format: (256, 256, 1)\n",
            "Output Format (mask): (256, 256, 1)\n",
            "Data type input: float64\n",
            "Data type output (mask): float64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input Format: {train_gen[0][0][0].shape}\\nOutput Format (mask): {train_gen[0][1][0].shape}\")\n",
        "print(f\"Data type input: {train_gen[0][0][0].dtype}\\nData type output (mask): {train_gen[0][1][0].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLSxsKRqoA-x",
        "outputId": "e80928d9-26fa-4d55-ff8d-3c70be8ab1fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.DataGenerator at 0x7f92871d9c30>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYzwLdFmKIFn"
      },
      "outputs": [],
      "source": [
        "def generador(directory, targets_dir, imgs, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        batch = imgs[index * batch_size : (index + 1) * batch_size]\n",
        "        x, y = np.empty((batch_size, 128, 128, 1)), np.empty((batch_size, 128, 128, 1))\n",
        "\n",
        "        for i, name in enumerate(batch):\n",
        "            path = directory + \"/\" + name\n",
        "            img = tf.keras.utils.load_img(path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "            img = tf.keras.utils.img_to_array(img)\n",
        "            x[i] = img / 255\n",
        "\n",
        "            target_path = targets_dir + \"/\" + name\n",
        "            target_img = tf.keras.utils.load_img(target_path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "            target_img = tf.keras.utils.img_to_array(target_img)\n",
        "            y[i] = target_img / 255\n",
        "\n",
        "        index += 1\n",
        "        if index == len(imgs) // batch_size:\n",
        "            index = 0\n",
        "        yield x, y\n",
        "\n",
        "dir_list = os.listdir(train_path_x)\n",
        "train_gen = generador(train_path_x, train_path_y, dir_list, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrNxBNXOKhjO"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Without generators </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzm1pb8mKhsn"
      },
      "source": [
        "Read all the images and leave them in a huge list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bRx5AMdCKIIG"
      },
      "outputs": [],
      "source": [
        "def load_img(img_path, gray=True):\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    return img / 255\n",
        "\n",
        "def load_dataset(directory):\n",
        "    dir_list = os.listdir(directory)\n",
        "    dir_len = len(dir_list)\n",
        "    imgs = np.empty((dir_len, 128, 128, 1))\n",
        "    for i, name in enumerate(dir_list):\n",
        "        name = directory + \"/\" + name\n",
        "        imgs[i] = load_img(name)\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solve problem with ._ files\n",
        "\n",
        "x_train = load_dataset(train_path_x)\n",
        "y_train = load_dataset(train_path_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "TetZsAx4oc0Z",
        "outputId": "8d7ebdc6-c646-4152-b149-a20f40198e41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3b073c5a4085>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8f2ac889a9d7>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8f2ac889a9d7>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(img_path, gray)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m     raise UnidentifiedImageError(\n\u001b[0m\u001b[1;32m   3031\u001b[0m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m     )\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f9287078f40>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmNdOW4LKIKV"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_train[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN3nrL0wLuH_"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>FSCN Model </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msuB8K4tLpYl"
      },
      "source": [
        "- We defined the model based on the conv-deconv architecture of the paper \"Fully Symmetric Convolutional Network for Effective\n",
        "Image Denoising\".\n",
        "\n",
        "- Returns a grayscale image. Then you have to do threshhold to see the bars well, so it is not very accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRYIwBLVLrBw"
      },
      "outputs": [],
      "source": [
        "#with tf.device('/device:GPU:0'):\n",
        "input_layer = Input(shape=(128, 128, 1), name=\"INPUT\")\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "output_layer = Conv2D(1, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(optimizer='adam', loss=\"mse\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp67lvEEL3b7"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Training </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ctjtcrvLxXp"
      },
      "outputs": [],
      "source": [
        "print(len(train_gen))\n",
        "\n",
        "def gen(seq):\n",
        "    i = 0\n",
        "    while True:\n",
        "        yield seq[i]\n",
        "        i += 1\n",
        "\n",
        "generador = gen(train_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi2ax7FtLxaU"
      },
      "outputs": [],
      "source": [
        "print(train_gen[0][0].shape)\n",
        "sys.getsizeof(train_gen[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpHWv0oPLxcv"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_gen,\n",
        "                    # y_train,\n",
        "                    # batch_size=BATCH_SIZE,\n",
        "                    steps_per_epoch=len(dir_list) // 64 - 1,\n",
        "                    verbose=1,\n",
        "                    epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO2eXpPtLxfP"
      },
      "outputs": [],
      "source": [
        "# from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Early Stopping\n",
        "# es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience = 5, restore_best_weights = True)\n",
        "\n",
        "#with tf.device('/device:GPU:0'):\n",
        "BATCH_SIZE = 64\n",
        "STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
        "EPOCHS = 20\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    verbose=1,\n",
        "                    epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wRuwizSME0O"
      },
      "source": [
        "<b><FONT size=\"5\" color='MidnightBlue '>Evaluation </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpuW9ZZMLxhF"
      },
      "outputs": [],
      "source": [
        "img_path = f\"{drive_path}segmentation-2/train/grises/{n}.png\"\n",
        "img = image.load_img(img_path, target_size=(256, 256), color_mode = \"grayscale\")\n",
        "img = tf.keras.utils.img_to_array(img) [:,:,0] / 255\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-7ZJdb2Lxjt"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, img_path):\n",
        "    \"Recibe un modelo y un path a una imagen y retorna la imagen y el output como np arrays\"\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "    img = tf.keras.utils.img_to_array(img) / 255\n",
        "    # print(img.shape)\n",
        "    segmented = model.predict(img)\n",
        "    return img[:,:,0], segmented[:,:,:,0]\n",
        "\n",
        "def normalize_img(img):\n",
        "    return (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "n = 10\n",
        "img_path = f\"{drive_path}segmentation-2/train/grises/{n}.png\"\n",
        "target_path = f\"{drive_path}segmentation-2/train/segmented/{n}.png\"\n",
        "\n",
        "img, segmented = evaluate(model, img_path)\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
        "fig.set_size_inches(15, 15)\n",
        "# plt.imshow(img)\n",
        "\n",
        "ax1.imshow(img, cmap=\"gray\")\n",
        "ax2.imshow(segmented[:,:,0], cmap=\"gray\")\n",
        "\n",
        "target = tf.keras.utils.load_img(target_path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "target = tf.keras.utils.img_to_array(target) [:,:,0]\n",
        "ax3.imshow(target, cmap=\"gray\")\n",
        "\n",
        "# print(segmented)\n",
        "ax4.imshow(normalize_img(segmented)[:,:,0], cmap=\"gray\")\n",
        "\n",
        "# print(normalize_img(segmented))\n",
        "# print(segmented)\n",
        "\n",
        "# print(segmented[150], img[150])\n",
        "\n",
        "# print(segmented[:, :, :, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wKn2O7TMKTE"
      },
      "outputs": [],
      "source": [
        "def save_model(model, name=None):\n",
        "    \"guarda un modelo como h5, si no tiene nombre se guarda con un timestamp\"\n",
        "    path = drive_path + \"models/\"\n",
        "    if name == None:\n",
        "        td = datetime.now()\n",
        "        name = f\"{td.year}-{td.year}-{td.day}_{td.hour}-{td.minute}-{td.second}\"\n",
        "    model.save(path + name + \".h5\", save_format=\"h5\")\n",
        "\n",
        "def load_model(model_path):\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "save_model(model, name=\"FSCN2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN22zbmnMKYG"
      },
      "outputs": [],
      "source": [
        "def show_data(model_path, img_path):\n",
        "    model = load_model(model_path) # CARGADO DEL MODELO\n",
        "    # IMG EN NP ARRAY (1, 256, 256, 1)\n",
        "    full_img = []\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=(128, 128), color_mode = \"grayscale\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    img = ((img - img.min())/(img.max() - img.min())) #MIN MAX\n",
        "    full_img.append(img)\n",
        "    full_img = np.array(full_img)\n",
        "    # PREDICCION\n",
        "    pred = model.predict(full_img)\n",
        "    # NORMALIZACIÓN\n",
        "    pred = ((pred - pred.min())/(pred.max() - pred.min()))\n",
        "\n",
        "    # THRESHOLD\n",
        "    thresh = cv2.threshold(pred[0,:,:,0], 0.8, 1, cv2.THRESH_BINARY)\n",
        "    thresh = thresh[1].reshape(256,256)\n",
        "\n",
        "    # ERODE-DILATE\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
        "    dilate = cv2.dilate(erosion, kernel, iterations = 1)\n",
        "\n",
        "    #DISPLAY\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.gray()\n",
        "    ax = plt.subplot(2,2,1)\n",
        "    plt.imshow(full_img.reshape(256,256))\n",
        "    ax = plt.subplot(2,2,2)\n",
        "    plt.imshow(pred.reshape(256,256))\n",
        "    ax = plt.subplot(2,2,3)\n",
        "    plt.imshow(thresh.reshape(256,256))\n",
        "    ax = plt.subplot(2,2,4)\n",
        "    plt.imshow(dilate.reshape(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pJ7umKEMKaU"
      },
      "outputs": [],
      "source": [
        "model_path = drive_path + \"models/FSCN1.h5\"\n",
        "n = 3\n",
        "img_path = f\"{drive_path}segmentation-2/test/grises/{n}.png\"\n",
        "target_path = f\"{drive_path}segmentation-2/train/segmented/{n}.png\"\n",
        "\n",
        "show_data(model_path, img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP59c-GnMKct"
      },
      "outputs": [],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHHvXiHDMKe3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLHxQ2Y2MKhl"
      },
      "outputs": [],
      "source": [
        "# Add load model here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eInpzPY4MKkD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "0spWGR09pFwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = load_model(model_path + '2021-2021-18_15-28-38.h5')\n",
        "m.summary()"
      ],
      "metadata": {
        "id": "fMZXc7a5pHxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(m)\n",
        "m.losses"
      ],
      "metadata": {
        "id": "d4r9LPTBpKIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(m)"
      ],
      "metadata": {
        "id": "pvDvmfAipKOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax(img):\n",
        "  img = (img - img.min())/(img.max() - img.min()) #MIN MAX\n",
        "  return img\n",
        "\n",
        "def test_model(model, img_path, img_shape, target_path=None):\n",
        "  # IMG EN NP ARRAY (1, 256, 256, 1)\n",
        "  # full_img = []\n",
        "  img = tf.keras.utils.load_img(img_path, target_size=(256,256), color_mode = \"grayscale\") #, interpolation=\"bicubic\")\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "  # img = minmax(img)\n",
        "\n",
        "  # PREDICCION\n",
        "  pred = model.predict(img[None,:,:,:]).reshape((256, 256))\n",
        "  img = img.reshape((256, 256))\n",
        "\n",
        "  # NORMALIZACIÓN\n",
        "  # pred = ((pred - pred.min())/(pred.max() - pred.min()))\n",
        "  # print(pred[0].shape)\n",
        "  # print(minmax(pred))\n",
        "  ret, thresh = cv2.threshold(minmax(pred), 0.5, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "  #DISPLAY\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  plt.gray()\n",
        "  ax = plt.subplot(2,2,1)\n",
        "  plt.imshow(img)\n",
        "  ax = plt.subplot(2,2,2)\n",
        "  plt.imshow(pred)\n",
        "  ax = plt.subplot(2,2,3)\n",
        "  plt.imshow(thresh)\n",
        "\n",
        "  # ax = plt.subplot(2,2,3)\n",
        "  # plt.imshow(1-new)\n",
        "  # ax = plt.subplot(2,2,4)\n",
        "  # plt.imshow(onepixel_img(new))\n",
        "  if target_path:\n",
        "    target = tf.keras.utils.load_img(target_path, target_size=(256,256), color_mode = \"grayscale\") #, interpolation=\"bicubic\")\n",
        "    target = tf.keras.utils.img_to_array(target)\n",
        "    ax = plt.subplot(2,2,4)\n",
        "    plt.imshow(target[:,:,0])"
      ],
      "metadata": {
        "id": "e-lMCa2PpKRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_path = None\n",
        "n = 1\n",
        "# img_path = drive_path + f\"dataset/segmentation-2/test/color/{n}.png\"\n",
        "img_path = drive_path + f\"ejemplos/internet/buenos/1000.jpg\"\n",
        "# target_path = drive_path + f\"dataset/segmentation-2/test/segmented/{n}.png\"\n",
        "\n",
        "# img_path = drive_path + \"DB graficos internet/Barras Verticales/Copia de graph_1003.jpg\"\n",
        "m = load_model(model_path + '2021-2021-18_15-28-38.h5')\n",
        "\n",
        "test_model(m, img_path, (256, 256), target_path)"
      ],
      "metadata": {
        "id": "0PtaZw60pKUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment(img_path, model):\n",
        "  img = tf.keras.utils.load_img(img_path, target_size=(256,256), color_mode = \"grayscale\") #, interpolation=\"bicubic\")\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "  # PREDICCION\n",
        "  pred = model.predict(img[None,:,:,:]).reshape((256, 256))\n",
        "  img = img.reshape((256, 256))\n",
        "\n",
        "  ret, thresh = cv2.threshold(minmax(pred), 0.5, 1, cv2.THRESH_BINARY)\n",
        "  return thresh.astype(np.uint8)\n",
        "\n",
        "  # m = load_model(model_path + models[0])"
      ],
      "metadata": {
        "id": "ius43eCkpKXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1016\n",
        "img_path = drive_path + f\"ejemplos/internet/buenos/{n}.jpg\"\n",
        "target_path = drive_path + f\"dataset/segmentation-2/test/segmented/{n}.png\"\n",
        "\n",
        "img_path = drive_path + \"models/dataset/DB graficos internet/Barras Verticales/Copia de graph_1003.jpg\"\n",
        "\n",
        "# print(segmented.astype(np.uint8).dtype)\n",
        "\n",
        "segmented = segment(img_path, m)\n",
        "\n",
        "# Invert de blanco con negro para encontrar los contours\n",
        "contours, hierarchy = cv2.findContours(np.where((segmented==0), 1, 0).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(segmented)\n",
        "\n",
        "img = cv2.drawContours(cv2.cvtColor(segmented * 255, cv2.COLOR_GRAY2RGB), contours, -1, (0,255,0), 1)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(img)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(cv2.drawContours(np.ones((256, 256, 3)) * 255, contours, -1, (0,255,0), 2))\n",
        "\n",
        "contours = [c for c in contours if c.shape[0] > 3]\n",
        "print(len(contours))\n",
        "# print(hierarchy)\n",
        "\n",
        "img = np.ones((256, 256, 3)) * 255\n",
        "for bar in contours:\n",
        "  x_min = bar[:,0,0].min()\n",
        "  x_max = bar[:,0,0].max()\n",
        "  y_min = bar[:,0,1].min()\n",
        "  y_max = bar[:,0,1].max()\n",
        "\n",
        "  cv2.rectangle(img,(x_min, y_min), (x_max, y_max), (0,255,0), 1)\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(img)\n"
      ],
      "metadata": {
        "id": "ZGxhPXgEpKar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_and_save():\n",
        "    pass\n",
        "\n",
        "def test_and_save_image(model, img_path, img_name, save_dir, display=True):\n",
        "\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=(256,256), color_mode = \"grayscale\") #, interpolation=\"bicubic\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "    # PREDICCION\n",
        "    pred = model.predict(img[None,:,:,:]).reshape((256, 256))\n",
        "    img = img.reshape((256, 256))\n",
        "\n",
        "    # NORMALIZACIÓN\n",
        "    ret, thresh = cv2.threshold(minmax(pred), 0.5, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Contornos\n",
        "    # Invert de blanco con negro para encontrar los contours\n",
        "    contours, hierarchy = cv2.findContours(np.where((thresh==0), 1, 0).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = [c for c in contours if c.shape[0] > 3]\n",
        "    # print(len(contours))\n",
        "\n",
        "    contour_img = np.ones((256, 256, 3)) * 255\n",
        "    final_img = tf.keras.utils.load_img(img_path, target_size=(256,256))\n",
        "    final_img = tf.keras.utils.img_to_array(final_img).astype(np.uint8)\n",
        "    # print(final_img.dtype)\n",
        "    for bar in contours:\n",
        "        x_min = bar[:,0,0].min()\n",
        "        x_max = bar[:,0,0].max()\n",
        "        y_min = bar[:,0,1].min()\n",
        "        y_max = bar[:,0,1].max()\n",
        "\n",
        "    cv2.rectangle(contour_img,(x_min, y_min), (x_max, y_max), (0,255,0), 1)\n",
        "    cv2.rectangle(final_img,(x_min, y_min), (x_max, y_max), (0,255,0), 2)\n",
        "\n",
        "    # DISPLAY\n",
        "    if display:\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.gray()\n",
        "        plt.subplot(2,3,1)\n",
        "        plt.imshow(img)\n",
        "        plt.subplot(2,3,2)\n",
        "        plt.imshow(pred)\n",
        "        plt.subplot(2,3,3)\n",
        "        plt.imshow(thresh)\n",
        "        plt.subplot(2, 3, 4)\n",
        "        plt.imshow(contour_img)\n",
        "        plt.subplot(2, 3, 5)\n",
        "        plt.imshow(final_img)\n",
        "\n",
        "    # Save\n",
        "    plt.imsave(save_dir + f\"1_grayscale_reshape/{img_name}\", img)\n",
        "    plt.imsave(save_dir + f\"2_output_red/{img_name}\", pred)\n",
        "    plt.imsave(save_dir + f\"3_threshold/{img_name}\", thresh)\n",
        "    plt.imsave(save_dir + f\"4_contornos/{img_name}\", contour_img / 255)\n",
        "    plt.imsave(save_dir + f\"5_contornos_sobre_original/{img_name}\", final_img)\n",
        ""
      ],
      "metadata": {
        "id": "qhpVK7TwpcK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_path = drive_path + f\"dataset/segmentation-2/test/segmented/{n}.png\"\n",
        "# test_and_save_image(m, img_path)\n",
        "imgs_path = drive_path + \"models/dataset/segmentation-2/test/color\"\n",
        "\n",
        "for img_name in os.listdir(imgs_path):\n",
        "  img_path = drive_path + f\"models/dataset/segmentation-2/test/color/{img_name}\"\n",
        "  save_dir = drive_path + \"models/dataset/segmentation-2/test/output/\"\n",
        "  test_and_save_image(m, img_path, img_name, save_dir, display=False)\n"
      ],
      "metadata": {
        "id": "Fign06x4pcOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_path = drive_path + \"models/dataset/internet/0_originales/\"\n",
        "\n",
        "for img_name in os.listdir(imgs_path):\n",
        "    img_path = imgs_path + img_name\n",
        "    save_dir = drive_path + \"models/dataset/internet/\"\n",
        "    test_and_save_image(m, img_path, img_name, save_dir, display=False)"
      ],
      "metadata": {
        "id": "bv9gQx2PpcQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9bEjR-4pcTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKnr_WE8pKcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNg0WUXhKpXfqLbm2/qR88C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}