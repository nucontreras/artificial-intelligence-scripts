{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nucontreras/artificial-intelligence-scripts/blob/main/FSCN/Lineas/line_chart_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W64CYScwd13"
      },
      "source": [
        "<b><FONT size=\"8\" color='264653'>Audiographics Project: sonification for the accessibility of quantitative information in graphic format </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSbhuvYwd8m"
      },
      "source": [
        "><b><FONT size=\"3\" color='DimGray'> Sonification for the accessibility of quantitative information in graphic format is part of the research line in Technology and Care of the Millennium Institute for Care Research ([MICARE](https://www.micare.cl/)). The objective of this project is to implement a tool for the transformation of quantitative information presented in visual form into audio to facilitate access to visually handicapped people, using sonification techniques and image analysis through artificial intelligence. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4YTrjY5cj8"
      },
      "source": [
        "><b><FONT size=\"3\" color='DimGray'> This file contains the processing, treatment and tests of a neural network used to filter line chart images. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hutlz3dT4NCx"
      },
      "source": [
        "><b><FONT size=\"3\" color='SlateGray'> Code edited from an old code made in an iPre. </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLo-jCPWyl8Q"
      },
      "source": [
        "# <b><FONT size=\"5\" color='MidnightBlue '>Connection to Google Drive </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFiF5dtmyl8T",
        "outputId": "18405cad-7827-4fb9-f989-0af84d76a717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/AudioGraphs\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd 'gdrive/MyDrive/AudioGraphs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7q5gU9-xX0v"
      },
      "source": [
        "#<b><FONT size=\"5\" color='MidnightBlue '>Import of packages </FONT>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "svJn-YTaHaA_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from random import shuffle, seed, randint\n",
        "import time\n",
        "\n",
        "# Data processing and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "\n",
        "# AI models\n",
        "import tensorflow as tf\n",
        "from keras.utils import Sequence, plot_model\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "\n",
        "seed(420)\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCF9jkMaFstr"
      },
      "source": [
        "<b><FONT size=\"4\" color='619b8a'>Path to bar chart images dataset  </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Leej0ZMZFth2"
      },
      "outputs": [],
      "source": [
        "path_line_chart_db = 'Codigos y BD anteriores/Lineas/test_procesado/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E1VfkbI1Qa4"
      },
      "source": [
        "<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93jhvnZk-HX"
      },
      "source": [
        "#<b><FONT color='MidnightBlue' size='6'>Neural network </FONT></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYCaTEKv7uHP"
      },
      "source": [
        "En primer lugar, se cargan datos de gráficos realizados en Python y Matlab de movimiento browniano entre 0 y 1, además de gráficos reales, tanto para el training como el testing de la red.\n",
        "\n",
        "Posterior a esto, se define a una red convolucional-deconvolucional tal como la observada en (*Fully Symmetric Convolutional Network for Effective Image Denoising*), donde se utilizarán las capas convolucionales para extraer las características principales de la imagen ignorando aquellos elementos a eliminar, y las capas deconvolucionales para la reconstrucción de la imagen como tal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDzmTLJFlVvz"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Definición de la red </FONT>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-MQ67dzlSxb",
        "outputId": "955dc6df-cf17-479b-8911-2ac17ae08c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " INPUT (InputLayer)          [(None, 256, 256, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      640       \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 256, 256, 64)     36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 256, 256, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " OUTPUT (Conv2D)             (None, 256, 256, 1)       577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 555,137\n",
            "Trainable params: 555,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    input_layer = Input(shape=(256, 256, 1), name=\"INPUT\")\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    output_layer = Conv2D(1, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(optimizer='adam', loss=\"mse\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZVUWAe2lbA6"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Clase del DataGenerator </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CSN3e3AKlS6T"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, list_IDs, batch_size=32, dim=(256, 256), n_channels=1, shuffle=True):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generar índices del batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Encontrar lista de IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generar Datos\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Actualiza los indices para cada epoch\n",
        "        # Tiene el shuffle en caso de que se active\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # Inicialización de datos\n",
        "        # X e y son de igual dimensión ya que ambos son imágenes\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "\n",
        "        # Generación de data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            img = tf.keras.utils.load_img(ID, target_size=(256, 256), color_mode=\"grayscale\", interpolation=\"bicubic\")\n",
        "\n",
        "            img = tf.keras.utils.img_to_array(img)\n",
        "            X[i,] = (img-img.min())/(img.max() - img.min())\n",
        "\n",
        "            # Store class\n",
        "            new_ID = ID.replace(\"full\", \"solo\")\n",
        "            img = tf.keras.utils.load_img(new_ID, target_size=(256, 256), color_mode=\"grayscale\", interpolation=\"bicubic\")\n",
        "\n",
        "            img = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "            y[i,] = (img-img.min())/(img.max() - img.min())\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l726bdGIlf5a"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Generación de lista de IDs </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gBf9v80SlS_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "49cfde85-55ed-4fbc-d4fe-94a48aea3606"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fbdb569abd64>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtest_full_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_line_chart_db\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'real_new/test/graficos-full/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_full_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Temporary solution for ._ problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'._'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Codigos y BD anteriores/Lineas/test_procesado/python/train/graficos-full/'"
          ]
        }
      ],
      "source": [
        "# GENERACION IDS para training y testing\n",
        "IDs_train = []\n",
        "IDs_test = []\n",
        "\n",
        "for op in range(1,2):\n",
        "    if op == 1:\n",
        "        train_full_path = path_line_chart_db + 'python/train/graficos-full/'\n",
        "        test_full_path = path_line_chart_db + 'python/test/graficos-full/'\n",
        "    elif op == 2:\n",
        "        train_full_path = path_line_chart_db + 'matlab/train/graficos-full/'\n",
        "        test_full_path = path_line_chart_db + 'matlab/test/graficos-full/'\n",
        "    elif op == 3:\n",
        "        train_full_path = path_line_chart_db + 'real_new/train/graficos-full/'\n",
        "        test_full_path = path_line_chart_db + 'real_new/test/graficos-full/'\n",
        "\n",
        "    for filename in os.listdir(train_full_path):\n",
        "        # Temporary solution for ._ problem\n",
        "        if '._' not in filename:\n",
        "            IDs_train.append(train_full_path + filename)\n",
        "\n",
        "    for filename in os.listdir(test_full_path):\n",
        "        # Temporary solution for ._ problem\n",
        "        if '._' not in filename:\n",
        "            IDs_test.append(test_full_path + filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A65eCXtjDV-l"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Training </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHr-M5_3lTDk"
      },
      "outputs": [],
      "source": [
        "# Early Stopping\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=15, restore_best_weights=True)\n",
        "\n",
        "# Parameters\n",
        "params = {'dim': (256, 256),\n",
        "          'batch_size': 32,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(IDs_train, **params)\n",
        "test_generator = DataGenerator(IDs_test, **params)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    history = model.fit(training_generator,\n",
        "                    steps_per_epoch=len(training_generator),\n",
        "                    epochs=150,\n",
        "                    shuffle=True, callbacks=[es])\n",
        "    #history = model.fit(X_train, Y_train,\n",
        "    #                batch_size = 32,\n",
        "    #                epochs=30,\n",
        "    #                shuffle=True) # callbacks=[es]\n",
        "\n",
        "loss = history.history['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb1qo94KlnFb"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/iPre_Graficos/modelos/final_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV7ZX-NnlnIL"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(loss)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tytZGpGFlnLP"
      },
      "outputs": [],
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=300,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7IhRRNLlnOe"
      },
      "outputs": [],
      "source": [
        "rec_test = model.predict(test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEOvY98TDrPo"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Testing </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9norcRDAlnQ_"
      },
      "outputs": [],
      "source": [
        "def minmax(img):\n",
        "    img = ((img - img.min())/(img.max() - img.min())) #MIN MAX\n",
        "    return img\n",
        "\n",
        "def onepixel_img(img):\n",
        "    onepix = np.ones(img.shape)\n",
        "    for i in range(img.shape[1]):\n",
        "        positions = np.where(img[:,i] == 1)\n",
        "        if len(positions[0]) >= 1:\n",
        "            onepix[int(np.sum(positions[0])/len(positions[0])), i] = 0\n",
        "    return onepix\n",
        "\n",
        "\n",
        "def show_data(model_path, img_path):\n",
        "    model = load_model(model_path) # CARGADO DEL MODELO\n",
        "    # IMG EN NP ARRAY (1, 256, 256, 1)\n",
        "    full_img = []\n",
        "    img = tf.keras.utils.load_img(img_path, color_mode = \"grayscale\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    final_shape = img.shape\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=(256,256), color_mode = \"grayscale\", interpolation=\"bicubic\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    img = minmax(img)\n",
        "    full_img.append(img)\n",
        "    full_img = np.array(full_img)\n",
        "    # PREDICCION\n",
        "    pred = model.predict(full_img)\n",
        "    # NORMALIZACIÓN\n",
        "    pred = ((pred - pred.min())/(pred.max() - pred.min()))\n",
        "\n",
        "    # THRESHOLD\n",
        "    _, thresh = cv2.threshold(pred[0,:,:,0], 0.5, 1, cv2.THRESH_BINARY_INV)\n",
        "    #print(thresh.shape)\n",
        "    #thresh = thresh[1].reshape(256,256)\n",
        "\n",
        "    # ERODE-DILATE\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    kernel2 = np.ones((4,4), np.uint8)\n",
        "    erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
        "    dilate = cv2.dilate(erosion, kernel, iterations = 1)\n",
        "    #open = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    open = cv2.erode(thresh, kernel, iterations = 0)\n",
        "    open = cv2.dilate(thresh, kernel, iterations = 1)\n",
        "\n",
        "    full_img = full_img.reshape((256,256))\n",
        "    pred = pred.reshape((256,256))\n",
        "    open = open.reshape((256,256))\n",
        "    thresh = thresh.reshape((256,256))\n",
        "    num_labels, labels_im = cv2.connectedComponents(np.uint8(open), connectivity = 8)\n",
        "    a = np.bincount(labels_im.flatten())[1:]\n",
        "    #print(a)\n",
        "    best_a = [i+1 for i,j in enumerate(a) if j >= 0.1*a.max()]\n",
        "    new = labels_im.copy()\n",
        "    #print(best_a)\n",
        "    for i in best_a:\n",
        "        new[labels_im == i] = 9999\n",
        "    new[new != 9999] = 0\n",
        "    new = new/9999\n",
        "    #new = minmax(new)\n",
        "    #print(np.uint8(open).max())\n",
        "\n",
        "    new = cv2.erode(new, kernel, iterations = 0)\n",
        "\n",
        "    thresh = cv2.resize(thresh, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_NEAREST)\n",
        "    pred = cv2.resize(pred, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    full_img = cv2.resize(full_img, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    open = cv2.resize(open, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    new = cv2.resize(new, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "\n",
        "    #thresh = minmax(thresh)\n",
        "    pred = minmax(pred)\n",
        "    full_img = minmax(full_img)\n",
        "    open = minmax(open)\n",
        "\n",
        "    # ONE PIXEL SOLO IMG\n",
        "    img_solo_path = img_path.replace(\"full\",\"solo\")\n",
        "    img_solo = tf.keras.utils.load_img(img_solo_path, color_mode = \"grayscale\")\n",
        "    img_solo = np.array(img_solo)\n",
        "    img_solo = minmax(img_solo)\n",
        "    _, img_solo = cv2.threshold(img_solo, 0.9, 1, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # CALCULAR DIFERENCIA VALORES REAL VS PRED\n",
        "\n",
        "    onepix = onepixel_img(new)\n",
        "    a, b = np.where(onepix == 0)\n",
        "    a = np.take_along_axis(a, np.argsort(b), axis=0)\n",
        "    b = np.take_along_axis(b, np.argsort(b), axis=0)\n",
        "    onepix_copy = onepix.copy()\n",
        "    for i in range(0, len(a) - 1):\n",
        "        dy = a[i+1] - a[i]\n",
        "        dx = b[i+1] - b[i]\n",
        "        if abs(dy) > 1:\n",
        "            delta_y = np.linspace(0,dy,abs(dy), dtype='int16')\n",
        "        if int(dx) == 1:\n",
        "            delta_x = np.linspace(0,1,abs(dy))\n",
        "            for k in range(abs(dy)):\n",
        "                if delta_x[k] < 0.5:\n",
        "                    delta_x[k] = 0\n",
        "                else:\n",
        "                    delta_x[k] = 1\n",
        "        else:\n",
        "            delta_x = np.linspace(0,dx,abs(dy), dtype = 'int16')\n",
        "        for j in range(1, abs(dy)):\n",
        "            onepix_copy[a[i] + int(delta_y[j]), b[i] + int(delta_x[j])] = 0\n",
        "\n",
        "    #for i in range(0, len(a) - 1):\n",
        "    #  posiciones = np.where(onepix[:,b[i] + 1] == 0)\n",
        "    #  if len(posiciones[0]) == 0:\n",
        "    #    delta_x = b[i+1] - b[i]\n",
        "    #    delta_y = a[i+1] - a[i]\n",
        "    #    delta_y = np.linspace(0,delta_y,delta_x, dtype='int8')\n",
        "        #print(delta_y)\n",
        "        #print(delta_x, delta_y)\n",
        "    #    for j in range(1, delta_x):\n",
        "    #      onepix_copy[a[i] + delta_y[j], b[i] + j] = 0\n",
        "    #DISPLAY\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.gray()\n",
        "    ax = plt.subplot(2,2,1)\n",
        "    plt.imshow(full_img)\n",
        "    ax = plt.subplot(2,2,2)\n",
        "    plt.imshow(1-new)\n",
        "    ax = plt.subplot(2,2,3)\n",
        "    plt.imshow(onepix_copy)\n",
        "    ax = plt.subplot(2,2,4)\n",
        "    plt.imshow(1-img_solo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fycto0s5lTH4"
      },
      "outputs": [],
      "source": [
        "# model_path = '/content/drive/My Drive/iPre_Graficos/modelos/test_gen_minmax_full_fix_16layer.h5'\n",
        "model_path = '/content/drive/My Drive/iPre_Graficos/modelos/final_1.h5'\n",
        "# model_path = '/content/last.h5'\n",
        "#model_path = '/content/drive/My Drive/iPre_Graficos/modelos/test_gen_minmax_full_fix2.h5'\n",
        "# img_path = \"/content/real_new/test/graficos-full/grafico-1.png\"\n",
        "img_path = \"/content/matlab/test/graficos-full/grafico-4010.png\"\n",
        "#img_path = '/content/descarga.jpg'\n",
        "show_data(model_path, img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoJR4y0dlTLc"
      },
      "outputs": [],
      "source": [
        "def minmax(img):\n",
        "    img = ((img - img.min())/(img.max() - img.min())) #MIN MAX\n",
        "    return img\n",
        "\n",
        "def onepixel_img(img):\n",
        "    onepix = np.ones(img.shape)\n",
        "    for i in range(img.shape[1]):\n",
        "        positions = np.where(img[:,i] == 1)\n",
        "        if len(positions[0]) >= 1:\n",
        "            onepix[int(np.sum(positions[0])/len(positions[0])), i] = 0\n",
        "    return onepix\n",
        "\n",
        "model_path = '/content/drive/My Drive/iPre_Graficos/modelos/final_1.h5'\n",
        "model = load_model(model_path) # CARGADO DEL MODELO\n",
        "\n",
        "img_path = \"/content/matlab/test/graficos-full/\"\n",
        "\n",
        "for filename in os.listdir(img_path):\n",
        "    # IMG EN NP ARRAY (1, 256, 256, 1)\n",
        "    full_img = []\n",
        "    img = tf.keras.utils.load_img(img_path + filename, color_mode = \"grayscale\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    final_shape = img.shape\n",
        "    img = tf.keras.utils.load_img(img_path + filename, target_size=(256,256), color_mode = \"grayscale\", interpolation=\"bicubic\")\n",
        "    img = tf.keras.utils.img_to_array(img)\n",
        "    img = minmax(img)\n",
        "    full_img.append(img)\n",
        "    full_img = np.array(full_img)\n",
        "    # PREDICCION\n",
        "    pred = model.predict(full_img)\n",
        "    # NORMALIZACIÓN\n",
        "    pred = ((pred - pred.min())/(pred.max() - pred.min()))\n",
        "\n",
        "    # THRESHOLD\n",
        "    _, thresh = cv2.threshold(pred[0,:,:,0], 0.5, 1, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # ERODE-DILATE\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    open = cv2.dilate(thresh, kernel, iterations = 1)\n",
        "\n",
        "    full_img = full_img.reshape((256,256))\n",
        "    pred = pred.reshape((256,256))\n",
        "    open = open.reshape((256,256))\n",
        "    thresh = thresh.reshape((256,256))\n",
        "    num_labels, labels_im = cv2.connectedComponents(np.uint8(open), connectivity = 8)\n",
        "    a = np.bincount(labels_im.flatten())[1:]\n",
        "    best_a = [i+1 for i,j in enumerate(a) if j >= 0.1*a.max()]\n",
        "    new = labels_im.copy()\n",
        "    for i in best_a:\n",
        "        new[labels_im == i] = 9999\n",
        "    new[new != 9999] = 0\n",
        "    new = new/9999\n",
        "\n",
        "    thresh = cv2.resize(thresh, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_NEAREST)\n",
        "    pred = cv2.resize(pred, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    full_img = cv2.resize(full_img, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    open = cv2.resize(open, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "    new = cv2.resize(new, (final_shape[1], final_shape[0]), interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "    # CALCULAR DIFERENCIA VALORES REAL VS PRED\n",
        "    onepix = onepixel_img(new)\n",
        "    a, b = np.where(onepix == 0)\n",
        "    a = np.take_along_axis(a, np.argsort(b), axis=0)\n",
        "    b = np.take_along_axis(b, np.argsort(b), axis=0)\n",
        "    onepix_copy = onepix.copy()\n",
        "    for i in range(0, len(a) - 1):\n",
        "        dy = a[i+1] - a[i]\n",
        "        dx = b[i+1] - b[i]\n",
        "        if abs(dy) > 1:\n",
        "            delta_y = np.linspace(0,dy,abs(dy), dtype='int16')\n",
        "        if int(dx) == 1:\n",
        "            delta_x = np.linspace(0,1,abs(dy))\n",
        "            for k in range(abs(dy)):\n",
        "                if delta_x[k] < 0.5:\n",
        "                    delta_x[k] = 0\n",
        "                else:\n",
        "                    delta_x[k] = 1\n",
        "        else:\n",
        "            delta_x = np.linspace(0,dx,abs(dy), dtype = 'int16')\n",
        "        for j in range(1, abs(dy)):\n",
        "            onepix_copy[a[i] + int(delta_y[j]), b[i] + int(delta_x[j])] = 0\n",
        "\n",
        "    # GUARDAR ARCHIVO PRED, OUT, OUT_ONEPIXEL\n",
        "    dir = f\"/content/matlab/pred/{filename}\"\n",
        "    im = Image.fromarray(255*pred)\n",
        "    im = im.convert(\"L\")\n",
        "    im.save(dir)\n",
        "    dir = f\"/content/matlab/out/{filename}\"\n",
        "    im = Image.fromarray(255*(1-new))\n",
        "    im = im.convert(\"L\")\n",
        "    im.save(dir)\n",
        "    dir = f\"/content/matlab/out_onepixel/{filename}\"\n",
        "    im = Image.fromarray(255*onepix_copy)\n",
        "    im = im.convert(\"L\")\n",
        "    im.save(dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBLd6-bll47h"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/python.zip /content/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ShNHBIl4-v"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/python.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1b4pEzNl5BW"
      },
      "outputs": [],
      "source": [
        "img = tf.keras.utils.load_img(\"/content/matlab/test/graficos-full/grafico-4017.png\", color_mode = \"grayscale\")\n",
        "img2 = tf.keras.utils.load_img(\"/content/matlab/test/graficos-full/grafico-4017.png\", target_size = (256,256), color_mode = \"grayscale\", interpolation = \"bicubic\")\n",
        "shape = np.array(img).shape\n",
        "print(np.array(img2).shape)\n",
        "#img = cv2.resize(np.array(img), (256,256), interpolation = cv2.INTER_CUBIC)\n",
        "img2 = cv2.resize(np.array(img2), (shape[1], shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "print(img2.shape)\n",
        "plt.imshow(img2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OcoEo3PD2px"
      },
      "source": [
        "##<b><FONT size=\"5\" color='MidnightBlue '>Capa a Capa </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbjaL91rl5D7"
      },
      "outputs": [],
      "source": [
        "#REVISAR CADA CAPA\n",
        "\n",
        "img_path = \"/content/python/train/graficos-full/grafico-36.png\"\n",
        "full_img = []\n",
        "img = tf.keras.utils.load_img(img_path, target_size=(256, 256), color_mode = \"grayscale\")\n",
        "img = tf.keras.utils.img_to_array(img)\n",
        "img = ((img - img.min())/(img.max() - img.min())) #MIN MAX\n",
        "full_img.append(img)\n",
        "full_img = np.array(full_img)\n",
        "\n",
        "# N° CAPA\n",
        "n = 10\n",
        "get_layer_output = K.function([model.layers[0].input], [model.layers[n].output])\n",
        "\n",
        "layer_output = get_layer_output([full_img])[0]\n",
        "print(layer_output.shape)\n",
        "plt.figure(figsize = (30,30))\n",
        "plt.gray()\n",
        "if n != 0 and n != 11:\n",
        "    for i in range(64):\n",
        "        plt.subplot(8,8,(i+1))\n",
        "        plt.imshow(layer_output[0,:,:,i])\n",
        "        plt.axis(False)\n",
        "else:\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.imshow(layer_output[0,:,:,0])\n",
        "    plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>"
      ],
      "metadata": {
        "id": "pFtZXpo-D7OU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KrSFJ9bZDyL"
      },
      "source": [
        "# <b><FONT size=\"7\" color='MidnightBlue '>Annexes </FONT>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmUyuE5YkrTA"
      },
      "outputs": [],
      "source": [
        "def BM(dt):\n",
        "    T = np.arange(0, 1 + dt, dt)\n",
        "    n = len(T)\n",
        "    B = np.ones(n) * 0\n",
        "    for i in range(n):\n",
        "        xi = np.sqrt(2) * (np.random.randn()) / ((i+0.5) * np.pi)\n",
        "        B = B + xi * np.array([np.sin((i + 0.5) * np.pi * t) for t in T])\n",
        "    return T, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "Ka18tgHmkrWI",
        "outputId": "6e9dfaf3-ca11-4bfa-fb66-5671e5d43e0e"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8f0dd950691f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Algo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#CREAR GRAFICO DE CUALQUIER COSA (?)\n",
        "n_points = 100\n",
        "#y = np.zeros((n_points,1))\n",
        "x = np.arange(0,n_points)\n",
        "#for i in range(n_points):\n",
        "y = BM(1/n_points)[1]\n",
        "y = y[1:]\n",
        "fig = plt.figure()\n",
        "#plt.ylim(-10,10) # FIJAR EL LIMITE\n",
        "plt.title(\"Hola\")\n",
        "plt.xlabel(\"Wena\")\n",
        "plt.grid()\n",
        "plt.xscale(\"log\")\n",
        "n = randint(0,n_points)\n",
        "plt.text(x[n],0,\"Algo\", fontsize = 14)\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nopl1AREkrZ2"
      },
      "outputs": [],
      "source": [
        "# GRAFICAR Y GUARDAR\n",
        "\n",
        "# https://stackoverflow.com/questions/7821518/matplotlib-save-plot-to-numpy-array\n",
        "# define a function which returns an image as numpy array from figure\n",
        "def get_img_from_fig(fig, dpi=180):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
        "    buf.close()\n",
        "    img = cv2.imdecode(img_arr, 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (256,256), interpolation=cv2.INTER_AREA)\n",
        "    return img\n",
        "\n",
        "# MOVIMIENTO BROWNIANO\n",
        "# http://cienciactuarial.blogspot.com/2017/12/simulacion-de-movimiento-browniano-con.html\n",
        "\n",
        "def BM(dt):\n",
        "    T = np.arange(0, 1 + dt, dt)\n",
        "    n = len(T)\n",
        "    B = np.ones(n) * 0\n",
        "    for i in range(n):\n",
        "        xi = np.sqrt(2) * (np.random.randn()) / ((i + 0.5) * np.pi)\n",
        "        B = B + xi * np.array([np.sin((i + 0.5) * np.pi * t) for t in T])\n",
        "    return T, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DROiBOAkrb5"
      },
      "outputs": [],
      "source": [
        "# CREACIÓN DE IMÁGENES\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "n_points = 100\n",
        "counter = 0\n",
        "x = np.arange(0,n_points)\n",
        "zip_counter = 6\n",
        "estilos = ['-','--', '-.', ':','']\n",
        "locs = ['upper left', 'upper right', 'lower left', 'lower right','upper center', 'lower center', 'center left', 'center right']\n",
        "titulos = [\"Title\", \"Plots\", \"Curves\", \"Experiments\", \"Time vs Something\"]\n",
        "palabras = [\"Experiment\", \"Wrong\", \"Correct\", \"Point\", \"Maximum\", \"Minimum\", \"Incorrect\", \"New Value\", \"Linear Function\", \"Irregular Curve\"]\n",
        "for ii in range(1):\n",
        "    for i in range(1000):#y.shape[1]\n",
        "        log = False\n",
        "        y = BM(1/n_points)[1]\n",
        "        y = y[1:]\n",
        "\n",
        "        # PLOT FIGURA ENTERA\n",
        "        fig = plt.figure()\n",
        "        #plt.ylim(-10,10) # FIJAR EL LIMITE\n",
        "        n1 = randint(0,4) # ESTILO GRILLA\n",
        "        n2 = randint(0,3) # ESTILO LINEA\n",
        "        #n3 = randint(0,1)\n",
        "        n4 = randint(1,2) # ANCHO GRILLA\n",
        "        n5 = randint(1,5) # ANCHO LINEA\n",
        "        #LEYENDA\n",
        "        n6 = randint(0,1) # SI HAY LEYENDA\n",
        "        n7 = randint(0,len(locs)-1) # UBICACION LEYENDA\n",
        "        n8 = randint(0,1) # FRAME LEYENDA\n",
        "        plt.grid(linestyle = estilos[n1], linewidth = n4)\n",
        "        plt.plot(x, y, linestyle = estilos[n2], linewidth=n5, label = 'Curve')\n",
        "        if n6 == 1:\n",
        "            plt.legend(loc = locs[n7], title = \"Legend\", frameon = (n8 == 1) )\n",
        "        if randint(0,1) == 1:\n",
        "            log = True\n",
        "            plt.xscale(\"log\")\n",
        "        plt.title(titulos[randint(0,len(titulos) - 1)] , fontsize = 18)\n",
        "        for k in range(5):\n",
        "            if randint(0,1) == 1:\n",
        "                break\n",
        "            else:\n",
        "                plt.text(x[randint(0,n_points - 10)], y[randint(0, n_points - 1)], palabras[randint(0, len(palabras) - 1)], fontsize = 16)\n",
        "        plt.xlabel(\"XLABEL\", fontsize = 14)\n",
        "        plt.ylabel(\"YLABEL\", fontsize = 14)\n",
        "\n",
        "\n",
        "        img = get_img_from_fig(fig)\n",
        "        plt.close()\n",
        "        dir = f\"/content/graficos-full/grafico-{str(1000*(zip_counter - 1) + i)}.png\"\n",
        "        cv2.imwrite(dir,img)\n",
        "\n",
        "        # PLOT FIGURA AISLADA\n",
        "        fig = plt.figure()\n",
        "        plt.plot(x, y)\n",
        "        plt.axis('off')\n",
        "        if log:\n",
        "            plt.xscale(\"log\")\n",
        "        img = get_img_from_fig(fig)\n",
        "        plt.close()\n",
        "        dir = f\"/content/graficos-solo/grafico-{str(1000*(zip_counter - 1) +  i)}.png\"\n",
        "        cv2.imwrite(dir,img)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "        if counter == 1000:\n",
        "            zipObj = ZipFile(f'/content/drive/My Drive/iPre_Graficos/graficos-full_zip_{zip_counter}.zip', 'w')\n",
        "            for j in range(1000):\n",
        "                zipObj.write(f'/content/graficos-full/grafico-{str(1000*(zip_counter - 1) + j)}.png')\n",
        "                os.remove(f'/content/graficos-full/grafico-{str(1000*(zip_counter - 1) + j)}.png')\n",
        "            zipObj.close()\n",
        "\n",
        "            zipObj = ZipFile(f'/content/drive/My Drive/iPre_Graficos/graficos-solo_zip_{zip_counter}.zip', 'w')\n",
        "            for j in range(1000):\n",
        "                zipObj.write(f'/content/graficos-solo/grafico-{str(1000*(zip_counter - 1) + j)}.png')\n",
        "                os.remove(f'/content/graficos-solo/grafico-{str(1000*(zip_counter - 1) + j)}.png')\n",
        "            zipObj.close()\n",
        "\n",
        "            zip_counter += 1\n",
        "            counter = 0\n",
        "\n",
        "elapsed = time.time() - t\n",
        "print(f\"Tiempo que se ha demorado: {elapsed} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0SZgIo65jE"
      },
      "source": [
        "<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Upc4wTlBco"
      },
      "source": [
        "### Cargado de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucquN8BzkreY"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/My Drive/iPre_Graficos/Final/graficos_new_4.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0nmUaLK3M6T"
      },
      "source": [
        "We don´t have this zip's file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnGafmG5lHsA"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbnsKYaekriZ"
      },
      "outputs": [],
      "source": [
        "!unzip train.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zURFsph3Xkj"
      },
      "source": [
        "We don´t have this zip's file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAPZ2hXvkrlN"
      },
      "outputs": [],
      "source": [
        "path_full = \"real/train/full/\"\n",
        "path_solo = \"real/train/solo/\"\n",
        "path_full_2 = \"real_new/train/graficos-full/\"\n",
        "path_solo_2 = \"real_new/train/graficos-solo/\"\n",
        "counter = 1\n",
        "counter_2 = 1\n",
        "for i in range(1, 40):\n",
        "    # PRIMERO\n",
        "    im = Image.open(path_full+str(i)+'.png')\n",
        "    im.save(f\"{path_full_2}grafico-{str(1 + (counter_2 - 1)*6)}.png\", quality=95)\n",
        "    im_solo = Image.open(path_solo+\"grafico-\"+str(1 + (counter_2 - 1)*5)+\".png\")\n",
        "    im_solo.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    # ROTATE\n",
        "    counter += 1\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # ROTATE\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # ROTATE\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # FLIP\n",
        "    im_rotate = ImageOps.flip(im)\n",
        "    im_solo_rotate = ImageOps.flip(im_solo)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # MIRROR\n",
        "    im_rotate = ImageOps.mirror(im)\n",
        "    im_solo_rotate = ImageOps.mirror(im_solo)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    counter_2 += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OHYX_5E6cMK"
      },
      "outputs": [],
      "source": [
        "path_full = \"real/test/full/\"\n",
        "path_solo = \"real/test/solo/\"\n",
        "path_full_2 = \"real_new/test/graficos-full/\"\n",
        "path_solo_2 = \"real_new/test/graficos-solo/\"\n",
        "counter = 1\n",
        "counter_2 = 1\n",
        "for i in range(40,50):\n",
        "    #PRIMERO\n",
        "    im = Image.open(path_full+str(i)+'.png')\n",
        "    im.save(f\"{path_full_2}grafico-{str(1 + (counter_2 - 1)*6)}.png\", quality=95)\n",
        "    im_solo = Image.open(path_solo+str(i)+\".png\")\n",
        "    im_solo.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    # ROTATE\n",
        "    counter += 1\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # ROTATE\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # ROTATE\n",
        "    ang = randint(1,360)\n",
        "    im_rotate = im.rotate(ang, expand=True)\n",
        "    im_solo_rotate = im_solo.rotate(ang, expand=True)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # FLIP\n",
        "    im_rotate = ImageOps.flip(im)\n",
        "    im_solo_rotate = ImageOps.flip(im_solo)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    # MIRROR\n",
        "    im_rotate = ImageOps.mirror(im)\n",
        "    im_solo_rotate = ImageOps.mirror(im_solo)\n",
        "    im_rotate.save(f\"{path_full_2}grafico-{counter}.png\", quality=95)\n",
        "    im_solo_rotate.save(f\"{path_solo_2}grafico-{counter}.png\", quality=95)\n",
        "    counter += 1\n",
        "    counter_2 += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy7iRRmnkrn1"
      },
      "outputs": [],
      "source": [
        "!zip -r \"/content/drive/My Drive/iPre_Graficos/Final/real_new.zip\" \"/content/real_new/\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}